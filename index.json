[{"categories":null,"content":"分布式id概述 在我们业务系统数据量不大的时候，单库单表完全可以支撑现有业务，数据再大一点搞个 MySQL 主从同步读写分离也能对付，这时候我们使用数据库自增id就足够了。 但随着业务数据日渐增长，主从同步也扛不住了，就需要对数据库进行分库分表，但分库分表后需要有一个唯一 ID 来标识一条数据，数据库的自增ID显然不能满足需求；还有就是某些场景需要唯一编号标识，比如订单号，用户编号等都需要有唯一 ID做标识。此时一个能够生成全局唯一 ID的系统是非常必要的。那么这个全局唯一 ID就叫分布式 ID。 ","date":"2025-12-20","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/:1:0","tags":null,"title":"分布式id解决方案","uri":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":null,"content":"分布式id的要求 全局唯一：必须保证 ID 是全局性唯一的，基本要求 高性能：高可用低延时，ID 生成响应要块，否则反倒会成为业务瓶颈 高可用：100% 的可用性是骗人的，但是也要无限接近于 100% 的可用性 好接入：要秉着拿来即用的设计原则，在系统设计和实现上要尽可能的简单 趋势递增：最好趋势递增，这个要求就得看具体业务场景了，一般不严格要求，如果是使用在业务数据库分库分表的分布式主键 ID，那边递增最后，如果只是用在唯一编号场景，并不太需要连续递增。 ","date":"2025-12-20","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/:1:1","tags":null,"title":"分布式id解决方案","uri":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":null,"content":"分布式id的实现方式 ","date":"2025-12-20","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/:2:0","tags":null,"title":"分布式id解决方案","uri":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":null,"content":"UUID 想要实现获取一个唯一 id 标识会立刻使用 UUID 实现，毕竟实现简单快捷，且满足唯一要求，实现如下： public static void main(String[] args) { String uuid = UUID.randomUUID().toString().replaceAll(\"-\",\"\"); System.out.println(uuid); } 但是使用 uuid 生成分布式 id，会有如下问题： 无序的字符串，不具备趋势自增特性 没有具体的业务含义，像订单号为 uuid 这样毫无意义的字符串，看不出和订单任何关联信息 长度过长 16 字节 128 位，36 位长度的字符串，存储以及查询对 MySQL 的性能消耗较大，MySQL 官方明确建议主键要尽量越短越好，作为数据库主键 UUID 的无序性会导致数据位置频繁变动，严重影响性能。 ","date":"2025-12-20","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/:2:1","tags":null,"title":"分布式id解决方案","uri":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":null,"content":"基于数据库自增ID 基于数据库的auto_increment自增 ID 完全可以充当分布式 ID，具体实现：需要一个单独的 MySQL 实例用来生成 ID，建表结构如下： CREATE DATABASE `SEQ_ID`; CREATE TABLE SEQID.SEQUENCE_ID ( id bigint(20) unsigned NOT NULL auto_increment, value char(10) NOT NULL default '', PRIMARY KEY (id), ) ENGINE=MyISAM; insert into SEQUENCE_ID(value) VALUES ('values'); 当我们需要一个 ID 的时候，向表中插入一条记录返回主键 ID，但这种方式有一个比较致命的缺点，访问量激增时 MySQL 本身就是系统的瓶颈，用它来实现分布式服务风险比较大，存在支持的并发量不大、数据库单点问题，不推荐！ ","date":"2025-12-20","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/:2:2","tags":null,"title":"分布式id解决方案","uri":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":null,"content":"基于数据库集群模式 前边说了单点数据库方式不可取，那对上边的方式做一些高可用优化，换成主从模式集群。害怕一个主节点挂掉没法用，那就做双主模式集群，也就是两个 Mysql实例都能单独的生产自增 ID。 那这样还会有个问题，两个 MySQL 实例的自增ID都从1开始，会生成重复的ID怎么办？ MySQL_1 配置： set @@auto_increment_offset = 1; -- 起始值 set @@auto_increment_increment = 2; -- 步长 MySQL_2 配置： set @@auto_increment_offset = 2; -- 起始值 set @@auto_increment_increment = 2; -- 步长 这样两个MySQL实例的自增ID分别就是： 1、3、5、7、9、11… 2、4、6、8、10、12… 那如果集群后的性能还是扛不住高并发咋办？就要进行 MySQL 扩容增加节点，这是一个比较麻烦的事。 增加第三台MySQL实例需要人工修改一、二两台MySQL实例的起始值和步长，把第三台机器的ID起始生成位置设定在比现有最大自增ID的位置远一些，但必须在一、二两台MySQL实例 ID 还没有增长到第三台MySQL实例的起始ID值的时候，否则自增ID就要出现重复了，必要时可能还需要停机修改。 ","date":"2025-12-20","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/:2:3","tags":null,"title":"分布式id解决方案","uri":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":null,"content":"基于数据库的号段模式 号段模式是当下分布式ID生成器的主流实现方式之一，号段模式可以理解为从数据库批量的获取自增ID，每次从数据库取出一个号段范围，例如 (1,1000] 代表1000 个 ID，具体的业务服务将本号段，生成 1~1000 的自增 ID 并加载到内存。表结构如下： CREATE TABLE id_generator ( id int(10) NOT NULL, max_id bigint(20) NOT NULL COMMENT '当前最大id', step int(20) NOT NULL COMMENT '号段的布长', biz_type int(20) NOT NULL COMMENT '业务类型', version int(20) NOT NULL COMMENT '版本号', PRIMARY KEY (`id`) ) biz_type ：代表不同业务类型 max_id ：当前最大的可用id step ：代表号段的长度 version ：是一个乐观锁，每次都更新 version，保证并发时数据的正确性 等这批号段 ID 用完，再次向数据库申请新号段，对max_id字段做一次update操作，update max_id = max_id + step，update 成功则说明新号段获取成功，新的号段范围是(max_id ,max_id +step]。 update id_generator set max_id = #{max_id + step}, version = version + 1 where version = # {version} and biz_type = XXX 由于多业务端可能同时操作，所以采用版本号version乐观锁方式更新，这种分布式ID生成方式不强依赖于数据库，不会频繁的访问数据库，对数据库的压力小很多。 ","date":"2025-12-20","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/:2:4","tags":null,"title":"分布式id解决方案","uri":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":null,"content":"基于redis实现 Redis也同样可以实现，原理就是利用redis的 incr命令实现ID的原子性自增 127.0.0.1:6379\u003e set seq_id 1 // 初始化自增ID为1 OK 127.0.0.1:6379\u003e incr seq_id // 增加1，并返回递增后的数值 (integer) 2 用redis实现需要注意一点，要考虑到 redis 持久化的问题，否则可能 id 重复使用问题 ","date":"2025-12-20","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/:2:5","tags":null,"title":"分布式id解决方案","uri":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":null,"content":"基于雪花算法（Snowflake）模式 雪花算法（Snowflake）是 twitter 公司内部分布式项目采用的 ID 生成算法，开源后广受国内大厂的好评，在该算法影响下各大公司相继开发出各具特色的分布式生成器。 Snowflake生成的是 Long 类型的ID，一个 Long 类型占8个字节，每个字节占 8 bit，也就是说一个 Long 类型占 64 个bit。 Snowflake ID 组成结构：正数位（占 1 bit）+ 时间戳（占 41 bit）+ 机器ID（占 5 bit）+ 数据中心（占 5 bit）+ 自增值（占 12 bit），总共 64 bit 组成的一个Long 类型。 第一个bit位（1bit）：Java 中 long 的最高位是符号位代表正负，正数是 0，负数是 1，一般生成 ID 都为正数，所以默认为 0。 时间戳部分（41bit）：毫秒级的时间，不建议存当前时间戳，而是用（当前时间戳 - 固定开始时间戳）的差值，可以使产生的 ID 从更小的值开始；41 位的时间戳可以使用 69 年，(1L « 41) / (1000L *60* 60 *24* 365) = 69 年 工作机器id（10bit）：也被叫做workId，这个可以灵活配置，机房或者机器号组合都可以。 序列号部分（12bit），自增值支持同一毫秒内同一个节点可以生成4096个ID 根据这个算法的逻辑，只需要将这个算法用 Java 语言实现出来，封装为一个工具方法，那么各个业务应用可以直接使用该工具方法来获取分布式 ID，只需保证每个业务应用有自己的工作机器 id 即可，而不需要单独去搭建一个获取分布式 ID 的应用。 package com.jerry.spring.common.util; import java.util.Objects; public class SnowFlakeUtil { /** * 起始的时间戳 */ private static Long START_TIMESTAMP = 1480166465631L; /** * 每一部分占用的位数 */ private final static long SEQUENCE_BIT = 12; //序列号占用的位数 private final static long MACHINE_BIT = 5; //机器标识占用的位数 private final static long DATA_CENTER_BIT = 5; //数据中心占用的位数 /** * 每一部分的最大值 */ private final static long MAX_SEQUENCE = ~(-1L \u003c\u003c SEQUENCE_BIT); private final static long MAX_MACHINE_NUM = ~(-1L \u003c\u003c MACHINE_BIT); private final static long MAX_DATA_CENTER_NUM = ~(-1L \u003c\u003c DATA_CENTER_BIT); /** * 每一部分向左的位移 */ private final static long MACHINE_LEFT = SEQUENCE_BIT; private final static long DATA_CENTER_LEFT = SEQUENCE_BIT + MACHINE_BIT; private final static long TIMESTAMP_LEFT = DATA_CENTER_LEFT + DATA_CENTER_BIT; private final long dataCenterId; //数据中心 private final long machineId; //机器标识 private long sequence = 0L; //序列号 private long lastTimeStamp = -1L; //上一次时间戳 private long getNextMill() { long mill = getNewTimeStamp(); while (mill \u003c= lastTimeStamp) { mill = getNewTimeStamp(); } return mill; } private long getNewTimeStamp() { return System.currentTimeMillis(); } /** * 根据指定的数据中心ID和机器标志ID生成指定的序列号 */ public SnowFlakeUtil(long dataCenterId, long machineId, Long startTimestamp) { if (dataCenterId \u003e MAX_DATA_CENTER_NUM || dataCenterId \u003c 0) { throw new IllegalArgumentException(\"DtaCenterId can't be greater than MAX_DATA_CENTER_NUM or less than 0！\"); } if (machineId \u003e MAX_MACHINE_NUM || machineId \u003c 0) { throw new IllegalArgumentException(\"MachineId can't be greater than MAX_MACHINE_NUM or less than 0！\"); } if (Objects.nonNull(startTimestamp)) { START_TIMESTAMP = startTimestamp; } this.dataCenterId = dataCenterId; this.machineId = machineId; } /** * 产生下一个ID */ public synchronized long nextId() { long currTimeStamp = getNewTimeStamp(); if (currTimeStamp \u003c lastTimeStamp) { throw new RuntimeException(\"Clock moved backwards. Refusing to generate id\"); } if (currTimeStamp == lastTimeStamp) { //相同毫秒内，序列号自增 sequence = (sequence + 1) \u0026 MAX_SEQUENCE; //同一毫秒的序列数已经达到最大 if (sequence == 0L) { currTimeStamp = getNextMill(); } } else { //不同毫秒内，序列号置为0 sequence = 0L; } lastTimeStamp = currTimeStamp; return (currTimeStamp - START_TIMESTAMP) \u003c\u003c TIMESTAMP_LEFT //时间戳部分 | dataCenterId \u003c\u003c DATA_CENTER_LEFT //数据中心部分 | machineId \u003c\u003c MACHINE_LEFT //机器标识部分 | sequence; //序列号部分 } public static void main(String[] args) { SnowFlakeUtil snowFlake = new SnowFlakeUtil(2, 3, 1735660800000L); for (int i = 0; i \u003c (1 \u003c\u003c 4); i++) { //10进制 System.out.println(snowFlake.nextId()); } } } ","date":"2025-12-20","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/:2:6","tags":null,"title":"分布式id解决方案","uri":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":null,"content":"百度（uid-generator） uid-generator是由百度技术部开发，项目GitHub地址 https://github.com/baidu/uid-generator uid-generator是基于Snowflake算法实现的，与原始的snowflake算法不同在于，uid-generator支持自定义时间戳、工作机器ID和序列号 等各部分的位数，而且uid-generator中采用用户自定义workId的生成策略。 uid-generator需要与数据库配合使用，需要新增一个WORKER_NODE表。当应用启动时会向数据库表中去插入一条数据，插入成功后返回的自增 ID 就是该机器的workId数据由 host，port 组成。 对于uid-generator ID组成结构： workId，占用了 22 个bit位，时间占用了 28 个bit位，序列化占用了 13 个bit位，需要注意的是，和原始的snowflake不太一样，时间的单位是秒，而不是毫秒，workId也不一样，而且同一应用每次重启就会消费一个workId。 ","date":"2025-12-20","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/:2:7","tags":null,"title":"分布式id解决方案","uri":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":null,"content":"美团（Leaf） leaf为叶子的意思，这名字源自世界上没有两片完全相同的树叶。https://tech.meituan.com/2017/04/21/mt-leaf.html mysql://localhost:3306/leaf_test?useUnicode=true\u0026characterEncoding=utf8\u0026characterSetResults=utf8 leaf.jdbc.username=root leaf.jdbc.password=root leaf.snowflake.enable=false #leaf.snowflake.zk.address= #leaf.snowflake.port= 启动leaf-server 模块的 LeafServerApplication项目就跑起来了 号段模式获取分布式自增 ID 的测试url ：http://localhost:8080/api/segment/get/leaf-segment-test 监控号段模式：http://localhost:8080/cache ","date":"2025-12-20","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/:2:8","tags":null,"title":"分布式id解决方案","uri":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":null,"content":"滴滴（Tinyid） Tinyid由滴滴开发，Github地址：https://github.com/didi/tinyid。 Tinyid是基于号段模式原理实现的与Leaf如出一辙，每个服务获取一个号段（1000,2000]、（2000,3000]、（3000,4000] ","date":"2025-12-20","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/:2:9","tags":null,"title":"分布式id解决方案","uri":"/%E5%88%86%E5%B8%83%E5%BC%8Fid%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":null,"content":"初识 Zookeeper ","date":"2024-09-12","objectID":"/zookeeper/:1:0","tags":null,"title":"认识 Zookeeper","uri":"/zookeeper/"},{"categories":null,"content":"ZooKeeper 概念 Zookeeper 是 Apache Hadoop 项目下的一个子项目，是一个树形目录服务。 Zookeeper 翻译过来就是 动物园管理员，他是用来管 Hadoop（大象）、Hive(蜜蜂)、Pig(小猪)的管理员。简称zk Zookeeper 是一个分布式的、开源的分布式应用程序的协调服务。 Zookeeper 提供的主要功能包括： 配置管理 分布式锁 集群管理 ","date":"2024-09-12","objectID":"/zookeeper/:1:1","tags":null,"title":"认识 Zookeeper","uri":"/zookeeper/"},{"categories":null,"content":"Zookeeper 数据模型 ZooKeeper 是一个树形目录服务,其数据模型和Unix的文件系统目录树很类似，拥有一个层次化结构。 这里面的每一个节点都被称为： ZNode，每个节点上都会保存自己的数据和节点信息。 节点可以拥有子节点，同时也允许少量（1MB）数据存储在该节点之下。 节点可以分为四大类： 持久化节点（PERSISTENT） 临时节点（EPHEMERAL）：-e 持久化顺序节点（PERSISTENT_SEQUENTIAL）：-s 临时顺序节点（EPHEMERAL_SEQUENTIAL）：-es ","date":"2024-09-12","objectID":"/zookeeper/:1:2","tags":null,"title":"认识 Zookeeper","uri":"/zookeeper/"},{"categories":null,"content":"Docker安装Zookeeper 查看本地镜像和检索拉取Zookeeper 镜像 # 查看本地镜像 docker images # 检索ZooKeeper 镜像 docker search zookeeper # 拉取ZooKeeper镜像最新版本 docker pull zookeeper:latest 创建ZooKeeper 挂载目录（数据挂载目录、配置挂载目录和日志挂载目录） mkdir -p /mydata/zookeeper/data # 数据挂载目录 mkdir -p /mydata/zookeeper/conf # 配置挂载目录 mkdir -p /mydata/zookeeper/logs # 日志挂载目录 启动ZooKeeper容器 docker run -d --name zookeeper --privileged=true -p 2181:2181 -v D:/Software/Docker/Zookeeper/data:/data -v D:/Software/Docker/Zookeeper/conf:/conf -v D:/Software/Docker/Zookeeper/logs:/datalog zookeeper:latest 参数说明 -e TZ=\"Asia/Shanghai\" # 指定上海时区 -d # 表示在一直在后台运行容器 -p 2181:2181 # 对端口进行映射，将本地2181端口映射到容器内部的2181端口 --name # 设置创建的容器名称 -v # 将本地目录(文件)挂载到容器指定目录； --restart always #始终重新启动zookeeper，看需求设置不设置自启动 添加ZooKeeper配置文件，在挂载配置文件目录(/mydata/zookeeper/conf)下，新增zoo.cfg 配置文件，配置内容如下： dataDir=/data # 保存zookeeper中的数据 clientPort=2181 # 客户端连接端口，通常不做修改 dataLogDir=/datalog tickTime=2000 # 通信心跳时间 initLimit=5 # LF(leader - follower)初始通信时限 syncLimit=2 # LF 同步通信时限 autopurge.snapRetainCount=3 autopurge.purgeInterval=0 maxClientCnxns=60 standaloneEnabled=true admin.enableServer=true server.1=localhost:2888:3888;2181 进入容器内部，验证容器状态 # 进入zookeeper 容器内部 docker exec -it zookeeper /bin/bash # 检查容器状态 docker exec -it zookeeper /bin/bash ./bin/zkServer.sh status # 进入控制台 docker exec -it zookeeper zkCli.sh ","date":"2024-09-12","objectID":"/zookeeper/:1:3","tags":null,"title":"认识 Zookeeper","uri":"/zookeeper/"},{"categories":null,"content":"ZooKeeper JavaAPI 操作 ","date":"2024-09-12","objectID":"/zookeeper/:2:0","tags":null,"title":"认识 Zookeeper","uri":"/zookeeper/"},{"categories":null,"content":"Curator 介绍 Curator 是 Apache ZooKeeper 的Java客户端库。 常见的ZooKeeper Java API ： 原生Java API ZkClient Curator Curator 项目的目标是简化 ZooKeeper 客户端的使用。 Curator 最初是 Netfix 研发的,后来捐献了 Apache 基金会,目前是 Apache 的顶级项目。 ","date":"2024-09-12","objectID":"/zookeeper/:2:1","tags":null,"title":"认识 Zookeeper","uri":"/zookeeper/"},{"categories":null,"content":"Curator API 常用操作 建立连接 引入依赖 \u003c!--curator--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.curator\u003c/groupId\u003e \u003cartifactId\u003ecurator-framework\u003c/artifactId\u003e \u003cversion\u003e4.0.0\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.curator\u003c/groupId\u003e \u003cartifactId\u003ecurator-recipes\u003c/artifactId\u003e \u003cversion\u003e4.0.0\u003c/version\u003e \u003c/dependency\u003e 创建测试类 import org.apache.curator.RetryPolicy; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.CuratorFrameworkFactory; import org.apache.curator.retry.ExponentialBackoffRetry; public class CuratorTest { public CuratorFramework getConnect() { /** * @param connectString 连接字符串，zk server地址和端口 \"127.0.0.1:2181\" * @param sessionTimeoutMs 会话超时时间，单位是毫秒ms * @param connectionTimeoutMs 连接超时时间，单位是毫秒ms * @param retryPolicy 重试策略 */ /* //重试策略 RetryPolicy retryPolicy = new ExponentialBackoffRetry(3000, 10); //第一种方式 CuratorFramework client = CuratorFrameworkFactory.newClient(\"127.0.0.1:2181\", 60 * 1000, 15 * 1000, retryPolicy); //开启连接 client.start(); */ //第二种方式,链式创建 RetryPolicy retryPolicy = new ExponentialBackoffRetry(3000, 10); CuratorFramework curatorFramework = CuratorFrameworkFactory.builder() .connectString(\"127.0.0.1:2181\") .sessionTimeoutMs(60 * 1000) .connectionTimeoutMs(15 * 1000) .retryPolicy(retryPolicy).namespace(\"smsService\").build(); curatorFramework.start(); return curatorFramework; } } 添加节点 public void createNode() throws Exception { CuratorFramework client = getConnect(); //基本创建 String path = client.create().forPath(\"/sztus\"); System.out.println(path); //带数据的创建 client.create().forPath(\"/sztus\",\"jerry_test\".getBytes(StandardCharsets.UTF_8)); //设置节点类型,临时类型，默认类型持久化 client.create().withMode(CreateMode.EPHEMERAL).forPath(\"/sztus\"); //创建多级节点 /app4/ios //creatingParentsIfNeeded,如果父节点不存在则创建父节点 client.create().creatingParentsIfNeeded().forPath(\"/sztus/azeroth\"); client.close(); } 删除节点 public void deleteNode() throws Exception { CuratorFramework client = getConnect(); //删除单个节点 client.delete().forPath(\"/sztus\"); //删除带有子节点的节点 client.delete().deletingChildrenIfNeeded().forPath(\"/sztus\"); //必须删除成功 client.delete().guaranteed().forPath(\"/sztus\"); //回调 client.delete().guaranteed().inBackground(new BackgroundCallback() { @Override public void processResult(CuratorFramework client, CuratorEvent event) throws Exception { System.out.println(\"被删除了\" + event); } }).forPath(\"/sztus\"); client.close(); } 修改节点 public void updateNode() throws Exception { CuratorFramework client = getConnect(); //简单修改数据 client.setData().forPath(\"/sztus\", \"sztus_test\".getBytes(StandardCharsets.UTF_8)); //判断版本信息一致再修改 Stat stat = new Stat(); client.getData().storingStatIn(stat).forPath(\"/sztus\"); int version = stat.getVersion(); client.setData().withVersion(version).forPath(\"/sztus\", \"sztus_test\".getBytes(StandardCharsets.UTF_8)); client.close(); } 查询节点 public void getNode() throws Exception { CuratorFramework client = getConnect(); //查询数据 get byte[] bytes = client.getData().forPath(\"/sztus\"); System.out.println(new String(bytes)); //查询子节点 ls List\u003cString\u003e path = client.getChildren().forPath(\"/\"); System.out.println(path); //查询节点状态信息 ls -s Stat stat = new Stat(); client.getData().storingStatIn(stat).forPath(\"/sztus\"); System.out.println(\"====\" +stat); client.close(); } Watch事件监听 ZooKeeper 允许用户在指定节点上注册一些 Watcher，并且在一些特定事件触发的时候，ZooKeeper 服务端会将事件通知到感兴趣的客户端上去，该机制是 ZooKeeper 实现分布式协调服务的重要特性。 ZooKeeper 中引入了 Watcher 机制来实现了发布/订阅功能能，能够让多个订阅者同时监听某一个对象，当一个对象自身状态变化时，会通知所有订阅者。 ZooKeeper 原生支持通过注册 Watcher来进行事件监听，但是其使用并不是特别方便 需要开发人员自己反复注册 Watcher，比较繁琐。 Curator 引入了 Cache 来实现对 ZooKeeper 服务端事件的监听。 NodeCache：只是监听某一个特点的节点 public void watchNode() { CuratorFramework client = getConnect(); CuratorCache cache = CuratorCache.build(client, \"/sztus/dolphin\", CuratorCache.Options.SINGLE_NODE_CACHE); CuratorCacheListener listener = CuratorCacheListener.builder() .forNodeCache(() -\u003e System.out.println(\"node change\")) .build(); client.close(); } PathChildrenCache : 监控一个 ZNode 的子节点.，感知不到自己的变化。 public void watchChildrenNode() { CuratorFramework curator = getConnect(); Cu","date":"2024-09-12","objectID":"/zookeeper/:2:2","tags":null,"title":"认识 Zookeeper","uri":"/zookeeper/"},{"categories":null,"content":"Zookeeper服务注册与发现 更改 pom 文件，增加 Zookeeper 的依赖 \u003cdependencies\u003e \u003c!-- 用于读取 bootstrap.yml --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-bootstrap\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- Sprint Boot Web Component --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- Sprint Boot Unit Test --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e \u003c!-- SpringBoot整合zookeeper客户端 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-zookeeper-discovery\u003c/artifactId\u003e \u003c/dependency\u003e 修改bootstrap.yml文件 # 9555表示注册到 zookeeper 服务器的支付服务提供者端口号 server: port: 9555 # 服务别名---- 注册 zookeeper 到注册中心名称 spring: application: name: cloud-zookeeper-server cloud: zookeeper: # 如果 zookeeper 是集群，指定多个地址即可：x.x.x.x:2181, y.y.y.y:2181 connect-string: localhost:2181 ","date":"2024-09-12","objectID":"/zookeeper/:3:0","tags":null,"title":"认识 Zookeeper","uri":"/zookeeper/"},{"categories":null,"content":"Zookeeper的分布式配置中心与监控 ","date":"2024-09-12","objectID":"/zookeeper/:4:0","tags":null,"title":"认识 Zookeeper","uri":"/zookeeper/"},{"categories":null,"content":"特点 节点 节点和关系都包含属性 关系链接节点 属性是键值对 节点用圆圈表示，关系用方向键表示 关系有方向：单向和双向 每个关系包含\"开始节点\"和\"到节点\"或\"结束节点\" ","date":"2024-03-20","objectID":"/neo4j/:1:0","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"主要元素 节点，属性，关系，标签，数据浏览器 ","date":"2024-03-20","objectID":"/neo4j/:2:0","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"基础语法 ","date":"2024-03-20","objectID":"/neo4j/:3:0","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"创建 CREATE：创建节点、关系和属性 ## create节点 CREATE (:student {name: \"小明\"} ),(:student {name: \"小红\"} ),(:student {name: \"张三\"} ) ## 建立关系 match (n:student {name: \"小明\"}),(m:student {name: \"小红\"}) create (n) - [r:同学] -\u003e (m) return n.name, type(r), m.name MATCH (n:city), (m:city_relation), (t:city) WHERE n.code = m.code AND m.subCode = t.code CREATE (n) - [r:`属于`] -\u003e (t) RETURN n.name, m.subName ","date":"2024-03-20","objectID":"/neo4j/:3:1","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"查询 MATCH：检索有关节点、关系和属性 ORDER BY ：排序检索数据 RETURN：返回查询结果 WHERE：提供条件过滤检索数据 ## 查询 MATCH (n:student) RETURN n LIMIT 25 ## 查询关系 MATCH relation = () -[r:`同学`] -\u003e () RETURN relation 查询两节点的之间的最短路径 match p = shortestpath((a)-[r*0..4]-(b)) where a.name = '刘备' and b.name='刘禅' return p 查询两节点的之间所有的最短路径 match p = allshortestpaths((a)-[r*0..4]-(b)) where a.name = '刘备' and b.name='刘禅' return p ","date":"2024-03-20","objectID":"/neo4j/:3:2","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"删除 DELETE：删除节点和关系 REMOVE：删除节点和关系的属性 ## 移除属性 MATCH (n:student) WHERE n.name = \"小明\" REMOVE n.sex ## 删除节点，删除节点前必须删除关系 MATCH(n:student) WHERE id(n) = 3 DELETE n ## 删除关系 MATCH (n:student) -[r] -\u003e (m:student) WHERE n.name = \"小明\" AND m.name = \"小红\" DELETE r ","date":"2024-03-20","objectID":"/neo4j/:3:3","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"更新 SET：添加或更新标签 ## 设置属性 MATCH (n:student) WHERE n.name = \"小明\" SET n.age = 20 ","date":"2024-03-20","objectID":"/neo4j/:3:4","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"Merge MERGE 语句非常适用于在插入或更新数据时进行模式匹配，它可以确保数据的一致性，同时避免重复创建相同的节点或关系。 MERGE 语句用于根据指定的模式进行创建或匹配节点和关系。如果节点或关系不存在时，创建它们，已存在时则进行匹配。 创建或匹配节点： ## 不存在时，创建；存在时，匹配（必须全部属性匹配） MERGE (p:person {name: '张三', age: '20', phone: '123456789', email:'zhangsan@qq.com'}) ## 如果存在数据，删除 MERGE (p:person {name: '张三', age: '20', phone: '18784417369', email:'zhangsan@qq.com'}) DELETE p ## 复杂查询 MATCH relation = (p1: person) - [r:Freid] -\u003e (p2: person) - [k:KNOWS] -\u003e (p3: person) RETURN relation ## 创建无向链接 MATCH (j:Person { name: '张三' }),(h:Person { name: '王五' }) MERGE (j)-[r:KNOWS]-(h) RETURN type(r) 创建或匹配带有多个标签的节点： ## 这个查询会检查是否已经存在一个带有 \"person\"和 \"man\"标签且属性为以下所示的节点。如果不存在，则创建一个新节点。 MERGE (p:person:man {name: '张三', age: '20', phone: '123456789', email:'zhangsan@qq.com'}) 创建或匹配关系及相关节点： 这个查询会首先检查是否已经存在两个具有 “Person” 标签的节点。然后它会检查两者是否有 “FRIEND” 关系，将这两个节点连接起来。 MERGE (a:person {name: '李四', age: '21', phone: '987654321', email:'lisi@qq.com'}); MERGE (b:person {name: '张三', age: '20', phone: '123456789', email:'zhangsan@qq.com'}); MERGE (a)-[:Freid]-\u003e(b); 条件性创建或匹配： 这个查询会检查是否已经存在一个具有 “Person” 标签且属性满足以下所示的节点。如果不存在，则创建一个新节点并设置 “age” 属性为 18。如果已存在，则更新 “phone” 属性。 MERGE (p:person {name: '张三', age: '20', phone: '123456789', email:'zhangsan@qq.com'}) ON CREATE SET p.age = '18' ON MATCH SET p.phone = '147852369' ","date":"2024-03-20","objectID":"/neo4j/:3:5","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"With with字句定义作用域变量，把with后面结果集当成一个查询结果、在这个结果基础上再做where条件的筛选或者候选的查询 WITH '刘备' AS a MATCH (p:Person) WHERE p.name = a RETURN p; MATCH (p:Person) - [r:兄弟] - (q:Person) WITH p, COUNT(q) AS people_count WHERE people_count \u003e 1 RETURN p.name,people_count 在with语句后，提前使用limit，限制查询的数据 MATCH (p:Person) WHERE p.group = \"蜀\" WITH p LIMIT 4 MATCH (p) -- (m:Person) WITH p, COLLECT(DISTINCT m.name) AS mName RETURN p.name, mName ","date":"2024-03-20","objectID":"/neo4j/:3:6","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"Unwind展开列表 unwind为列表的每个元素返回一行，如：某节点有个属性为列表，UNWIND将列表中的元素迭代，每个元素返回一个结果 WITH ['刘备', '孙权', '曹操'] AS names UNWIND names AS name MATCH (p:Person {name: name}) RETURN p ","date":"2024-03-20","objectID":"/neo4j/:3:7","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"Call执行子查询 子查询是一组在其自己的范围内执行的 Cypher 语句。子查询通常从外部封闭查询调用。使用子查询，可以限制需要处理的行数。 CALL { MATCH (p1:Person) WHERE p1.group = \"蜀\" RETURN p1 } MATCH (p1) - [r:兄弟] - (p2:Person) RETURN p2 ","date":"2024-03-20","objectID":"/neo4j/:3:8","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"Foreach 循环操作，常用于批量更新节点的数据 ## 更新/新增子节点的属性 MATCH p = (n:city) - [r:`属于`] -\u003e (m:city) WHERE n.name = '广东省' FOREACH (item IN nodes(p) | SET m.marked = '9527') ","date":"2024-03-20","objectID":"/neo4j/:3:9","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"Index索引 使用INDEX创建或者删除索引 ## 创建索引 CREATE index on : personal (name) ## 删除索引 DROP index on : personal (name) ","date":"2024-03-20","objectID":"/neo4j/:3:10","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"Unique约束 避免创建重复的数据 ## 创建约束 CREATE constraint on (n:personal) assert n.name is unique ## 删除约束 DROP constraint on (n:personal) assert n.name is unique ","date":"2024-03-20","objectID":"/neo4j/:3:11","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"断言函数 all，用于判断list中的所有元素，是否满足where条件 return all(x in [1,2,3,4] where x%2=0) //返回false return all(x in [1,2,3,4, null] where x%2=0) //返回false any，用于判断list中，是否存在一个满足where条件的元素 return any(x in [] where x%2=0) //返回false return any(x in [null] where x%2=0) //返回null return any(x in [2.0] where x%2=0) //返回true exist，用于判断，是否存在某个属性或者关系 MATCH (p:person) WHERE exists(p.name) RETURN p.name AS name, exists((p)-[:LIVE_IN]-\u003e()) AS live none，用于判断list中的每一个元素，是否都不满足where条件 return none(x in [1,3] where x%2=0) //返回true return none(x in [1,3, null] where x%2=0) //返回null single，用于判断list中，只有一个元素满足条件 return single(x in [6,null] where x%2=0) //返回null ","date":"2024-03-20","objectID":"/neo4j/:3:12","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"标量函数 coalesce，返回参数中第一个不为null的值，如果都为null，则返回null。 MATCH (p:person) RETURN coalesce(p.name, p.age) startNode：用于知道关系的开始节点 endNode：用于知道关系的结束节点 MATCH () -[r:LIVE_IN] -\u003e () RETURN startNode(r), endNode(r) id：用于知道关系的ID type：用于知道字符串表示种的一个关系的TYPE labels：用于返回节点的标签 MATCH () -[r:LIVE_IN] -\u003e () RETURN id(r), type(r) head：返回list的第一个元素 last：返回list的最后一个元素 return head([3,null,1,2,3]) //返回3 return head([]) //返回null randomUUID：用于随机生成长度为32的唯一uuid return REPLACE(randomuuid(), '-', '') length：返回路径的长度 length也可以用于计算string、list、pattern的长度，但是强烈建议只对path使用length，对其它类型长度的计算功能，后续可能被丢弃。 MATCH relation = (p:person) -[*1..5] -\u003e (m:person) RETURN relation, length(relation) size：用法根据参数的类型确定 size(string)：表示字符串中字符的数量，可以把字符串当作是字符的列表。 size(list)：返回列表中元素的数量。 size(pattern_expression)：也是统计列表中元素的数量 MATCH relation = (p:person) -[*1..5] -\u003e (m:person) RETURN m.name, size(m.name), size([1,2,null,4]), size((m) --\u003e ()) MATCH (p1:person), (p2:person) WHERE p1.name = '王五' AND p2.name = '李四' RETURN size((p2) --\u003e (p1)) RETURN size([1,2,null,4]) //返回4 MATCH (p:Person) - [r:下属] -\u003e (m:Person) RETURN size(collect(m)) properties：用于返回节点或者关系的全部属性 timestamp：用于返回当前的时间戳 ","date":"2024-03-20","objectID":"/neo4j/:3:13","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"字符串函数 left和right，用于获取字符串左边/右边，规定长度的子字符串 MATCH (n:person) WHERE n.name = '李四' RETURN left(n.phone, 2) ltrim、rtrim、trim，去除字符串左边、右边、两边的空格 RETURN ltrim(\" Hello Word \"), rtrim(\" Hello Word \"), trim(\" Hello Word \") replace：replace(original, search, replace)，使用replace替换original中的所有search字符串 MATCH (n:person) WHERE n.name = '李四' RETURN replace(n.phone, '2', '1') reverse：字符串翻转 split：字符串拆分 substring：字符串切割 toLower、toUpper：用于字符串的大小写转换 MATCH (n:person) WHERE n.name = '李四' RETURN reverse(n.phone) MATCH (n:person) WHERE n.name = '李四' RETURN split(n.phone, '5') MATCH (n:person) WHERE n.name = '李四' RETURN substring(n.phone, 5) MATCH (n:person) WHERE n.name = '李四' RETURN toUpper(n.name) RETURN toUpper('Jerry'), toLower('Jerry') contains：判断字符串是否包含另一个字符串，注意区分大小写 RETURN 'Hello Word' contains 'Hello' nodes：用于返回路径上的所有节点 MATCH relation = (p1: person) -[r:LIVE_IN] -\u003e (l1: location) RETURN nodes(relation) MATCH p =(a)--\u003e(b)--\u003e(c) WHERE a.name = '李四' RETURN nodes(p) relationships：返回路径上的所有关系 MATCH p =(a)--\u003e(b)--\u003e(c) WHERE a.name = '李四' RETURN relationships(p), nodes(p) reduce：返回每个元素作用于表达式上的结果 MATCH p =(a)--\u003e(b)--\u003e(c) WHERE a.name = '李四' RETURN reduce(totalAge = 0, n IN nodes(p)| totalAge + id(n)) AS reduction 使用正则表达式进行匹配 RETURN 'Hello Word' =~ 'Hello.*' ","date":"2024-03-20","objectID":"/neo4j/:3:14","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"数值函数 abs：取绝对值 floor：向下取整 ceil：向上取整 round：四舍五入 rand：返回一个（0, 1）的随机数 sign：返回数值的正负，如果值为零，则返回0。如果值为负数，则返回-1。如果值为正数，返回1。 RETURN abs(-101), floor(3.5), ceil(3.5), round(3.4) RETURN round(3.4), round(3.5) RETURN rand(), sign(-1), sign(0), sign(1) ","date":"2024-03-20","objectID":"/neo4j/:3:15","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"导入CSV文件 ## 导入csv文件并创建节点 load csv from \"file:///city.csv\" as row create (n:city {code:row[1], name:row[2], administrativeDivision:row[0]}) return count(n) load csv from \"file:///city_relation.csv\" as row create (n:city_relation {code:row[0], name:row[1], subCode:row[2], subName:row[3]}) return count(n) ","date":"2024-03-20","objectID":"/neo4j/:3:16","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"时间函数 date格式：yyyy-mm-dd datetime格式：yyyy-mm-ddThh:MM:SS:sssZ localdatetime格式：yyyy-mm-ddThh:MM:SS:sss localtime格式：hh:MM:SS.sss time格式：hh:MM:SS.sssZ ","date":"2024-03-20","objectID":"/neo4j/:4:0","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"获取时间 获取当前时间，可以指定时区 date([{timezone}]) datetime([{timezone}]) localdatetime([{timezone}]) localtime([{timezone}]) time([{timezone}]) RETURN date() RETURN date({timezone: 'America/Los Angeles'}) 使用transaction时返回当前时间。对于同一事务中的每次调用，该值都是相同的 date.transaction([{timezone}]) datetime.transaction([{timezone}]) localdatetime.transaction([{timezone}]) localtime.transaction([{timezone}]) time.transaction([{timezone}]) RETURN date.transaction() 使用statement返回当前时间。对于同一语句中的每次调用，该值都相同。但是，同一事务中的不同语句可能会产生不同的值 date.statement([{timezone}]) datetime.statement([{timezone}]) localdatetime.statement([{timezone}]) localtime.statement([{timezone}]) time.statement([{timezone}]) RETURN date.statement() 使用时间返回当前值realtime。该值将是系统的实时时钟 date.realtime([{timezone}]) datetime.realtime([{timezone}]) localdatetime.realtime([{timezone}]) localtime.realtime([{timezone}]) time.realtime([{timezone}]) RETURN date.realtime() ","date":"2024-03-20","objectID":"/neo4j/:4:1","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"创建时间 以年-月-日的格式创建时间 date({year [, month, day]}) datetime({year [, month, day, hour, minute, second, millisecond, microsecond, nanosecond, timezone]}) localdatetime({year [, month, day, hour, minute, second, millisecond, microsecond, nanosecond]}) RETURN date({year: 2024, month: 4, day: 24}) 以年-周-日的格式创建时间 date({year [, week, dayOfWeek]}) datetime({year [, week, dayOfWeek, hour, minute, second, millisecond, microsecond, nanosecond, timezone]}) localdatetime({year [, week, dayOfWeek, hour, minute, second, millisecond, microsecond, nanosecond]}) RETURN date({year: 2024, week: 17, dayOfWeek: 3}) 以年-季度-日的格式创建时间 date({year [, quarter, dayOfQuarter]}) datetime({year [, quarter, dayOfQuarter, hour, minute, second, millisecond, microsecond, nanosecond, timezone]}) localdatetime({year [, quarter, dayOfQuarter, hour, minute, second, millisecond, microsecond, nanosecond]}) RETURN date({year: 2024, quarter: 2, dayOfQuarter: 24}) 以年-日的格式创建时间 date({year [, ordinalDay]}) datetime({year [, ordinalDay, hour, minute, second, millisecond, microsecond, nanosecond, timezone]}) localdatetime({year [, ordinalDay, hour, minute, second, millisecond, microsecond, nanosecond]}) RETURN date({year: 2024, ordinalDay: 115}) 根据字符串创建时间 date(temporalValue) datetime(temporalValue) RETURN date('2024-04-24'),date('2024-04'),date('202404'),date('2024-W17-3'),date('20240424'),date('2024') RETURN datetime('2015-07-21T21:40:32.142+0100'), datetime('2015-W30-2T214032.142Z'), datetime('2015T214032-0100'), datetime('20150721T21:40-01:30'), datetime('2015-W30T2140-02'), datetime('2015202T21+18:00'), datetime('2015-07-21T21:40:32.142[Europe/London]'), datetime('2015-07-21T21:40:32.142-04[America/New_York]') return localdatetime('2015-07-21T21:40:32.142'), localdatetime('2015-W30-2T214032.142'), localdatetime('2015-202T21:40:32'), localdatetime('2015202T21') 根据时间戳创建时间 datetime({ epochSeconds | epochMillis }) ## 注意，这里默认的时区是UTC协调世界时 return datetime({epochSeconds: timestamp() / 1000, nanosecond: 23}), datetime({epochMillis: 1713950965318}) 使用其他时间格式创建另一种时间格式的时间 date({date [, year, month, day, week, dayOfWeek, quarter, dayOfQuarter, ordinalDay]}) datetime({datetime [, year, ..., timezone]}) | datetime({date [, year, ..., timezone]}) | datetime({time [, year, ..., timezone]}) | datetime({date, time [, year, ..., timezone]}) localdatetime({datetime [, year, ..., nanosecond]}) | localdatetime({date [, year, ..., nanosecond]}) | localdatetime({time [, year, ..., nanosecond]}) | localdatetime({date, time [, year, ..., nanosecond]}) UNWIND [ date({year: 1984, month: 11, day: 11}), localdatetime({year: 1984, month: 11, day: 11, hour: 12, minute: 31, second: 14}), datetime({year: 1984, month: 11, day: 11, hour: 12, timezone: '+01:00'}) ] as dd RETURN date({date: dd}) as dateOnly, date({date: dd, day: 28}) as dateDay; WITH date({year: 1984, month: 10, day: 11}) as dd RETURN datetime({date: dd, hour: 10, minute: 10, second: 10}) as dateHHMMSS, datetime({date: dd, day: 28, hour: 10, minute: 10, second: 10, timezone:'Pacific/Honolulu'}) as dateDDHHMMSSTimezone; ","date":"2024-03-20","objectID":"/neo4j/:4:2","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"分割时间 WITH datetime({ year: 2024, month: 4, day: 24, hour: 12, minute: 31, second: 14, nanosecond: 645876123, timezone: '+01:00' }) as d RETURN date.truncate('millennium', d) as truncMillenium, datetime.truncate('century', d) as truncCentury, date.truncate('decade', d) AS truncDecade, date.truncate('year', d, {day: 5}) AS truncYear, date.truncate('weekYear', d) as truncWeekYear, date.truncate('quarter', d) as truncQuarter, date.truncate('month', d) as truncMonth, date.truncate('week', d, {dayOfWeek: 2}) as truncWeek, date.truncate('day', d) as truncDay, datetime.truncate('hour', d) as truncHour, datetime.truncate('minute', d) as truncMinute, datetime.truncate('second', d) as truncSecond, datetime.truncate('millisecond', d) as truncMillisecond, datetime.truncate('microsecond', d) as truncMicrosecond ","date":"2024-03-20","objectID":"/neo4j/:4:3","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"特殊查询 无向关系的查询，在Neo4J中，关系的创建不能是无向的，但是查询和使用可以，因此可以这样查询和修改关系 MATCH (m:Person) - [r2:兄弟] - (n:Person) RETURN DISTINCT m ","date":"2024-03-20","objectID":"/neo4j/:5:0","tags":null,"title":"Neo4j文档","uri":"/neo4j/"},{"categories":null,"content":"什么是ETCD? Etcd是一个基于go语音实现，用于共享配置和服务发现的分布式储存系统，在分布式系统中提供强一致性、高可用性的功能。它提供了一种可靠的方式来存储需要被分布式系统或机器集群访问的数据。Etcd操作简单，使用Http请求的方式，对数据读取和写入，它将数据存储在分层组织的目录中；并且监听特定的key或者目录，根据需求做出相应的反应。 基于Etcd提供的api，可以实现以下几个功能： 服务注册与发现 配置管理 消息发布和订阅 负载均衡 分布式锁、分布式队列 集群监控 leader选举（基于raft算法） Etcd主要分为4个部分： Http Server：用于处理用户发送的API请求以及其它Etcd节点的同步和心跳信息请求。 Store：用于处理Etcd支持的各类功能事务，包括数据索引、节点状态更新、监控与反馈、事件处理与执行等等，是etcd对用户提供的大多数API功能的具体实现。 Raft：Raft是强一致性算法的具体实现，是Etcd的核心。 WAL：Write Ahead Log（预写式日志），是Etcd的数据储存方式。除了在内存中存有所有数据的状态以及节点的索引以外，Etcd就通过WAL进行持久化存储。WAL中，所有的数据提交前都会事先记录日志。Snapshot是为了防止数据过多而进行的状态快照；Entry表示存储的具体日志内容。 ","date":"2023-06-09","objectID":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/:1:0","tags":null,"title":"Kubernetes 的注册中心和配置中心(Etcd))","uri":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/"},{"categories":null,"content":"环境准备 WSL(Windows Subsystem for Linux) 为使用Kind准备环境，让环境虚拟化 Kind(Kubernetes In Docker) 下载Kind ，下载地址。Kind是绿色软件，下载后改名 kind.exe放到 C:\\Windows\\目录下即可。 Kubectl kubectl是管理Kubernetes集群的命令行工具，下载kubectl，下载地址。下载后放到 C:\\Windows\\目录下即可。 Docker 安装Docker，官网下载安装包，一路下一步安装即可。安装之后，需要打开一次来确认安装是否成功。 ","date":"2023-06-09","objectID":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/:2:0","tags":null,"title":"Kubernetes 的注册中心和配置中心(Etcd))","uri":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/"},{"categories":null,"content":"Kubernetes的注册中心 ","date":"2023-06-09","objectID":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/:3:0","tags":null,"title":"Kubernetes 的注册中心和配置中心(Etcd))","uri":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/"},{"categories":null,"content":"注册中心对比 目前java生态中，主流的注册中心有：Eureka、Nacos、Zookeeper、Consul、Etcd。其中，Etcd和Consul是Go语言开发的，Eureka、Nacos、Zookeeper都是Java开发的。目前这5个注册中心都有相对应的boot start，提供了集成能力。 ","date":"2023-06-09","objectID":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/:3:1","tags":null,"title":"Kubernetes 的注册中心和配置中心(Etcd))","uri":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/"},{"categories":null,"content":"Spring微服务集成Kubernetes的注册中心 maven依赖配置 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-kubernetes-client-all\u003c/artifactId\u003e \u003cversion\u003e${kubernetes}\u003c/version\u003e \u003c/dependency\u003e 服务的yml配置 szt: service: name: azeroth-provider port: 8811 server: port: ${szt.service.port} spring: application: name: ${szt.service.name} 在启动类上加EnableDiscoveryClient注解 @SpringBootApplication @EnableDiscoveryClient public class AzerothProviderApplication { public static void main(String[] args) { SpringApplication.run(AzerothProviderApplication.class, args); } } 添加Controller类，使用DiscoveryClient获取服务及其参数 @RestController public class ProviderController { @Autowired private DiscoveryClient discoveryClient; /** * 获取所有服务id */ @GetMapping(\"/service\") public List\u003cString\u003e getServiceList() { return discoveryClient.getServices(); } /** * 获取服务信息 */ @GetMapping(\"/instance\") public Object getInstance(@RequestParam(\"name\") String name) { return discoveryClient.getInstances(name); } /** * 获取所有服务及其信息 */ @GetMapping(\"/service-information\") public List\u003cList\u003cServiceInstance\u003e\u003e getServiceInformation() { List\u003cString\u003e list = discoveryClient.getServices(); List\u003cList\u003cServiceInstance\u003e\u003e result = new ArrayList\u003cList\u003cServiceInstance\u003e\u003e(); for (String name : list) { List\u003cServiceInstance\u003e instances = discoveryClient.getInstances(name); result.add(instances); } return result; } @GetMapping(\"/hello\") public String test() { return \"Provider Server\"; } } DiscoveryClient是Spring Cloud Commons提供的一个接口，负责服务的发现和注册，Kubernetes有一个实现类KubernetesInformerDiscoveryClient，因此可以Kubernetes可以与Spring Cloud完美衔接。 将镜像加载到kubernetes中 kind load docker-image provider:v4 --name=aztus 编写provider.yaml，创建deployment控制器和对外桥接的service apiVersion: apps/v1 kind: Deployment metadata: name: provider namespace: default labels: app: provider spec: replicas: 1 selector: matchLabels: app: provider template: metadata: labels: app: provider spec: containers: - name: provider image: docker.io/library/provider:v4 env: - name: spring.profiles.active value: develop ports: - name: rest containerPort: 8811 hostPort: 8811 --- apiVersion: v1 kind: Service metadata: name: provider namespace: default labels: app: provider spec: type: NodePort selector: app: provider ports: - name: rest protocol: TCP port: 8811 targetPort: 8811 nodePort: 30001 部署deployment和service kubectl apply -f provider.yaml 调用接口，查看kubernetes注册中心中的服务以及服务的详细信息 http://localhost:30001/service [ \"provider\", \"kubernetes\" ] http://localhost:30001/instance?name=provider [ { \"instanceId\": \"4a6e734a-0628-4000-8522-0d39d021aa08\", \"serviceId\": \"provider\", \"host\": \"10.244.0.6\", \"port\": 8811, \"uri\": \"http://10.244.0.6:8811\", \"secure\": false, \"metadata\": { \"app\": \"provider\", \"kubectl.kubernetes.io/last-applied-configuration\": \"{\\\"apiVersion\\\":\\\"v1\\\",\\\"kind\\\":\\\"Service\\\",\\\"metadata\\\":{\\\"annotations\\\":{},\\\"labels\\\":{\\\"app\\\":\\\"provider\\\"},\\\"name\\\":\\\"provider\\\",\\\"namespace\\\":\\\"default\\\"},\\\"spec\\\":{\\\"ports\\\":[{\\\"name\\\":\\\"rest\\\",\\\"nodePort\\\":30001,\\\"port\\\":8811,\\\"protocol\\\":\\\"TCP\\\",\\\"targetPort\\\":8811}],\\\"selector\\\":{\\\"app\\\":\\\"provider\\\"},\\\"type\\\":\\\"NodePort\\\"}}\\n\", \"rest\": \"8811\" }, \"namespace\": \"default\", \"cluster\": null, \"scheme\": \"http\" } ] 到这里，我们就已经将我们的服务注册到kubernetes的注册中心上了。 ","date":"2023-06-09","objectID":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/:4:0","tags":null,"title":"Kubernetes 的注册中心和配置中心(Etcd))","uri":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/"},{"categories":null,"content":"Feign的调用 接下来，我们简单说一下Feign的集成，看一看服务与服务之间的调用。 编写另一个服务consumer，服务的配置与provider的配置一样。controller层不同 @RestController @Slf4j public class ConsumerController { @Autowired private ProviderApi providerApi; @GetMapping(\"/hello\") public String hello() { log.info(\"[Consumer Log] hello method\"); return providerApi.hello(); } } 编写providerApi @FeignClient(value = \"provider\", path = \"\", contextId = \"provider-api\") public interface ProviderApi { @GetMapping(\"/hello\") String hello(); } 现在我们将服务部署到kubernetes集群中，就可以用consumer调用provider提供的服务了 kind load docker-image consumer:v4 --name=sztus kubectl create deployment consumer --image=docker.io/library/consumer:v4 --port=8812 kubectl create service nodeport consumer --tcp=8812:8812 --node-port=30002 http://localhost:30002/hello Provider Server 可以看到，我们提供consumer服务，成功调用到了provider提供的服务 ","date":"2023-06-09","objectID":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/:4:1","tags":null,"title":"Kubernetes 的注册中心和配置中心(Etcd))","uri":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/"},{"categories":null,"content":"Spring微服务集成Kubernetes的配置中心（configmap） pom文件的依赖与注册中心一直 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-kubernetes-client-all\u003c/artifactId\u003e \u003cversion\u003e${kubernetes}\u003c/version\u003e \u003c/dependency\u003e yml配置 szt: service: name: azeroth-config port: 8813 server: port: ${szt.service.port} spring: cloud: kubernetes: reload: enabled: true mode: polling period: 500 config: sources: - name: ${szt.configmap} # szt.configmap和spring.profiles.active，设置在deployment的部署文件中 namespace: default # 指定kubernetes的namespace，建议也写在deployment的部署文件中 application: name: ${szt.service.name} 编写controller层的代码 @RestController public class ConfigController { @Autowired private CustomerService customerService; @Value(\"${greeting.message:null}\") private String greeting; @Value(\"${database.url:null}\") private String database; /** * 如果开启kubernetes的健康检查，会定时调用此接口 */ @GetMapping(\"/health\") public String health() { return \"success\"; } @GetMapping(\"/config/hello\") public String hello() { return greeting; } @GetMapping(\"/config/database\") public String database() { return database; } } 通过kind创建kubernetes集群，并将镜像加载到集群中 kind load docker-image config:v4 --name=sztus # 将docker镜像config，加载到sztus的kubernetes集群中 接下来，我们需要将我们的配置加载到configmap中，先准备两份yml文件 develop的配置，在/configmap/develop下创建azeroth-config.yml文件 greeting: message: Hello config map for development database: url: This is the link to the development database release的配置，在/configmap/release下创建azeroth-config.yml文件 greeting: message: Hello config map for production farewell: message: Here is the link to the production database 分别将两份文件加载到两个configmap中 # 使用当前目录下的configmap中的develop文件夹中的所有配置，加载到configmap-develop中 kubectl create configmap configmap-develop --from-file=configmap/develop # 使用当前目录下的configmap中的develop文件夹中的所有配置，加载到configmap-release中 kubectl create configmap configmap-release --from-file=configmap/release 查看加载的配置 $ kubectl get configmap # 查看所有的configmap NAME DATA AGE configmap-develop 1 2d3h configmap-release 1 2d16h kube-root-ca.crt 1 2d16h $ kubectl describe configmap configmap-develop # 查看某个具体的configmap信息 Name: configmap-develop Namespace: default Labels: \u003cnone\u003e Annotations: \u003cnone\u003e Data ==== azeroth-config.yml: ---- greeting: message: Hello config map for development database: url: This is the link to the development database BinaryData ==== Events: \u003cnone\u003e 到这一步，我们就已经把所有的配置加载到kubernetes的配置中心里了。接下来我们需要启动服务，去获取配置中心中的配置，先创建一个控制器。 创建控制器deployment的配置：config.yaml apiVersion: apps/v1 kind: Deployment metadata: name: config labels: app: config spec: replicas: 3 selector: matchLabels: app: config template: metadata: labels: app: config spec: containers: - name: config image: docker.io/library/config:v4 # 这里是用kind加载到集群中的镜像名 env: - name: spring.profiles.active # 设置服务的环境 value: develop - name: szt.configmap # yml配置中的configmap参数，指定从那个configmap中读取配置文件 value: configmap-develop ports: - containerPort: 8813 使用kubectl部署控制器deployment和service kubectl apply -f config.yaml # 通过config.yaml创建或者更新deployment kubectl create service nodeport config --tcp=8813:8813 --node-port=30003 # 创建一个service 通过service访问接口，查看运行结果 http://localhost:30003/config/hello Hello config map for development 附加： ","date":"2023-06-09","objectID":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/:5:0","tags":null,"title":"Kubernetes 的注册中心和配置中心(Etcd))","uri":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/"},{"categories":null,"content":"基于系统和注册中心的特性（CAP） 本节内容，主要是探索目前主要的分布式、一致性键值数据存储软件性能的对比，通过对Etcd、Zookeeper和Consul多个层面的对比，我们可以全面地了解 ","date":"2023-06-09","objectID":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/:6:0","tags":null,"title":"Kubernetes 的注册中心和配置中心(Etcd))","uri":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/"},{"categories":null,"content":"Kubernetes介绍 ","date":"2023-06-09","objectID":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/:7:0","tags":null,"title":"Kubernetes 的注册中心和配置中心(Etcd))","uri":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/"},{"categories":null,"content":"组件介绍 Namespace K8S集群中默认的Namespace为default，通过Namespace可以实现Pod之间的相互隔离（如测试环境、生成环境的隔离） 通过K8S的资源配置机制限定不同的Namespace对CPU、内存的使用，再通过K8S授权机制将不同的Namespace交给不同的租户进行管理，实现多租户资源的隔离 Kubernetes默认自带的命名空间 default 未指定命名空间的对象都会被分配到该空间 kube-node-lease 集群节点之间的心跳维护 kube-public 此命名空间下的资源可以被所有用户访问 kube-system 由K8S系统创建的资源都会被分配到该空间 kubectl create ns [命名空间名称] # 创建命名空间 kubectl get ns # 查询命名空间 kubectl delete ns [命名空间名称] --force --grace-period=0 # 删除命名空间，该空间下的所有资源也将被删除 Label Label通过K-V的形式在资源上添加标识，用它来对资源（Node、Pod、Service）进行区分和选择，实现资源的多纬度分组，以便灵活、方便地进行资源分配、调度、配置和部署等管理 常用的标签：frontend、backend、dev、test、release、stable kubectl label pod [Pod名称] -n [命名空间] version=1.0 # 给Pod添加标签（version=1.0） kubectl label pod [Pod名称] -n [命名空间] version=2.0 --overwrite # 给Pod更新标签（version=2.0） kubectl label pod [Pod名称] -n [命名空间] version- # 给Pod删除标签（version） kubectl get pod nginx -n [命名空间] --show-labels # 查看Pod（nginx）的标签 kubectl get pod -l \"version=1.0\" -n dev --show-labels # 筛选Pod中标签为version=1.0 kubectl get pod -l \"version!=3.0\" -n default --show-labels # 筛选Pod中标签为version!=3.0 kubectl get pod -l \"version in (1.0,3.0)\" -n default --show-labels # 筛选Pod中标签为version是1.0或者3.0 kubectl get pod -l \"version=1.0， app=nginx\" -n default --show-labels # 筛选Pod中标签为version是1.0并且app是nginx的 Pod Pod是k8s集群进行管理的最小单元，程序运行在容器中，容器运行在于Pod中，一个Pod中可以运行一个或多个容器 Pod更新策略 重建更新（创建新的Pod前，会删除所有已经存在的Pod） 滚动更新（历史版本逐步替换新版本，最终新版本全部覆盖历史版本） kubectl run [Pod名称] --image=[镜像名称] --port=[端口] --namespace=[命名空间] # 创建并运行一个pod（不推荐直接运行Pod） kubectl delete pod [Pod名称] -n [命名空间] --force --grace-period=0 # 删除pod kubectl get pod -n [命名空间] -o wide # 查询所有Pod的基本信息 kubectl describe pod [Pod名称] -n [命名空间] # 查看Pod的详细信息 kubectl logs -f [Pod名称] -n [命名空间] # 查看pod的日志 Deployment（Pod控制器） Deployment用于管理无状态的应用，支持滚动升级、回退 通过Pod直接运行容器，会有以下缺点： Pod重建后IP会变化，外部无法得知最新的IP 业务应用无法启动多个副本 运行业务Pod的某个节点挂了，无法实现故障转移、恢复 Pod是K8S的最小控制单元，但K8S并不直接控制Pod，而通过Deployment来操作Pod Deployment用于对Pod进行管理，确保Pod资源符合预期的状态（当Pod资源出现故障时，会尝试对Pod进行重启或重建） 通过命令直接删除Pod，Pod会在控制器的作用下重新创建并启动 通过命令直接删除Deployment，该控制器下的所有Pod都会被删除 通过命令直接删除NameSpace，该命名空间下的所有Deployment、Pod都会被删除 ReplicaSet：保证指定数量的Pod正常运行，一旦Pod发生故障就会重启或重建，同时还支持Pod的扩容、缩容以及镜像版本的升级 kubectl create deployment [deployment名称] --image=[镜像] -n [命名空间] # 创建deployment，会自动创建相应的Pod kubectl scale deployment [deployment名称] --replicas=2 -n [命名空间] # 将deployment下的pod扩容到2个 kubectl describe deployment [deployment名称] -n [命名空间] # 查看deployment的详细信息 kubectl delete deployment [deployment名称] -n [命名空间] # 删除deployment，级联删除其下的所有pod kubectl apply -f deployment.yaml --record # 创建deployment，会根据yaml文件自动创建相应的Pod kubectl get -f deployment.yaml # 查询Deployment kubectl delete -f deployment.yaml # 删除deployment，级联删除其下的所有pod kubectl set image deploy [deployment名称] [image名称]=[镜像版本] -n [命名空间] # 调整deployment下的Pod镜像版本 kubectl set image deploy tomcat tomcat=tomcat:jdk11 kubectl rollout undo deploy [deployment名称] --to-revision=1 -n [命名空间] # 回退deployment下Pod镜像的版本 kubectl rollout status deploy [deployment名称] -n [命名空间] # 回退状态 kubectl rollout history deploy [deployment名称] -n [命名空间] # 回退历史记录 # 基于现有Pod的CPU利用率选择要运行的Pod个数下限和上限 kubectl autoscale deployment/nginx-deployment --min=10 --max=15 --cpu-percent=80 Service K8S 可以保证任意 Pod 挂掉时自动从任意节点启动一个新的Pod进行代替，以及某个Pod超负载时动态对Pod进行扩容。每当 Pod 发生变化时其 IP地址也会发生变化，且Pod只有在K8S集群内部才可以被访问，为了解决Pod发生变化导致其IP动态变化以及对外无法访问的问题，K8S引进了 Service 的概念 K8S 使用 Service 来管理同一组标签下的 Pod ，当外界需要访问 Pod 中的容器时，只需要访问 Service 的这个虚拟 IP 和端口，由 Service 把外界的请求转发给它背后的Pod kubectl get service -o wide -n [命名空间] # 查询service # 创建service kubectl create service nodeport [自定义名字] --tcp=80:80[service端口号:pod端口号] --node-port=31000[nodePort端口号] ClusterIP：自动为当前Service分配虚拟IP，在不重启Service前提下该IP是不会改变的，只能在集群内部访问 NodePort：需要在K8S集群的所有 Node 节点上开放特定的端口【30000-32767】，通过（公网ip : 端口）访问Service服务。缺点：每个端口只能挂载一个Service service创建成功后会通过api-server向etcd中写入相关配置信息，kube-proxy会监听创建好的配置信息并将最新的service配置信息转化成对应的访问规则，最终实现外网对Pod的访问。常见的service访问规则有：iptables 和ipvs iptables：kube-proxy为service后端的每个Pod创建对应的iptables规则，当用户访问ClusterIP时，直接将发送到ClusterIP的请求重定向到Pod ipvs：kube-proxy 监控Pod的变化并创建相应的ipvs规则，当用户访问ClusterIP时，直接将发送到ClusterIP的请求重定向到Pod，较复杂，需要单独安装 kub","date":"2023-06-09","objectID":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/:7:1","tags":null,"title":"Kubernetes 的注册中心和配置中心(Etcd))","uri":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/"},{"categories":null,"content":"探究与发现 服务升级 kubernetes是如何友好的对服务进行版本升级的？ 我们先创建一个deployment，对应维护3个pod kubectl create deployment nginx --image=nginx --port=80 --replicas=3 如果某一天，我们发现当前版本存在一定问题，需要进行升级版本 kubectl set image deployment/nginx nginx=nginx:1.16.1 服务是如何升级的 kubectl describe deployments Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 23m deployment-controller Scaled up replica set nginx-ff6774dc6 to 3 Normal ScalingReplicaSet 97s deployment-controller Scaled up replica set nginx-7f6dff8469 to 1 Normal ScalingReplicaSet 93s deployment-controller Scaled down replica set nginx-ff6774dc6 to 2 from 3 Normal ScalingReplicaSet 93s deployment-controller Scaled up replica set nginx-7f6dff8469 to 2 from 1 Normal ScalingReplicaSet 90s deployment-controller Scaled down replica set nginx-ff6774dc6 to 1 from 2 Normal ScalingReplicaSet 90s deployment-controller Scaled up replica set nginx-7f6dff8469 to 3 from 2 Normal ScalingReplicaSet 87s deployment-controller Scaled down replica set nginx-ff6774dc6 to 0 from 1 可以看到，当第一次创建Deployment时，它创建了一个ReplicaSet(nginx-ff6774dc6) 并将其直接扩容至3个副本。更新Deployment时，它创建了一个新的ReplicaSet(nginx-7f6dff8469)，并将其扩容为1，等待其就绪；然后将旧ReplicaSet缩容到12， 将新的ReplicaSet扩容到2以便至少有3个 Pod 可用且最多创建4个Pod。 然后，它使用相同的滚动更新策略继续对新的ReplicaSet扩容并对旧的ReplicaSet缩容。 最后，你将有3个可用的副本在新的ReplicaSet中，旧ReplicaSet将缩容到0。 ","date":"2023-06-09","objectID":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/:7:2","tags":null,"title":"Kubernetes 的注册中心和配置中心(Etcd))","uri":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/"},{"categories":null,"content":"yml文件编写 使用ymal文件对组件操作 kubectl apply -f [文件名].ymal # 使用文件去创建某个组件 kubectl get -f [文件名].ymal # 使用文件去查询某个组件 kubectl edit deployment/nginx-deployment # 更改deployment的配置 kubectl delete -f [文件名].ymal # 通过文件去删除某个组件 Pod文件定义 apiVersion: v1 #必选，版本号，例如v1,版本号必须可以用 kubectl api-versions 查询到 . kind: Pod #必选，Pod metadata: #必选，元数据 name: string #必选，Pod名称 namespace: string #必选，Pod所属的命名空间,默认为\"default\" labels: #自定义标签 - name: string #自定义标签名字 annotations: #自定义注释列表 - name: string spec: #必选，Pod中容器的详细定义 containers: #必选，Pod中容器列表 - name: string #必选，容器名称,需符合RFC 1035规范 image: string #必选，容器的镜像名称 imagePullPolicy: [ Always|Never|IfNotPresent ] #获取镜像的策略 Alawys表示下载镜像 IfnotPresent表示优先使用本地镜像,否则下载镜像，Nerver表示仅使用本地镜像 command: [string] #容器的启动命令列表，如不指定，使用打包时使用的启动命令 args: [string] #容器的启动命令参数列表 workingDir: string #容器的工作目录 volumeMounts: #挂载到容器内部的存储卷配置 - name: string #引用pod定义的共享存储卷的名称，需用volumes[]部分定义的的卷名 mountPath: string #存储卷在容器内mount的绝对路径，应少于512字符 readOnly: boolean #是否为只读模式 ports: #需要暴露的端口库号列表 - name: string #端口的名称 containerPort: int #容器需要监听的端口号 hostPort: int #容器所在主机需要监听的端口号，默认与Container相同 protocol: string #端口协议，支持TCP和UDP，默认TCP env: #容器运行前需设置的环境变量列表 - name: string #环境变量名称 value: string #环境变量的值 resources: #资源限制和请求的设置 limits: #资源限制的设置 cpu: string #Cpu的限制，单位为core数，将用于docker run --cpu-shares参数 memory: string #内存限制，单位可以为Mib/Gib，将用于docker run --memory参数 requests: #资源请求的设置 cpu: string #Cpu请求，容器启动的初始可用数量 memory: string #内存请求,容器启动的初始可用数量 livenessProbe: #对Pod内各容器健康检查的设置，当探测无响应几次后将自动重启该容器，检查方法有exec、httpGet和tcpSocket，对一个容器只需设置其中一种方法即可 exec: #对Pod容器内检查方式设置为exec方式 command: [string] #exec方式需要制定的命令或脚本 httpGet: #对Pod内个容器健康检查方法设置为HttpGet，需要制定Path、port path: string port: number host: string scheme: string HttpHeaders: - name: string value: string tcpSocket: #对Pod内个容器健康检查方式设置为tcpSocket方式 port: number initialDelaySeconds: 0 #容器启动完成后首次探测的时间，单位为秒 timeoutSeconds: 0 #对容器健康检查探测等待响应的超时时间，单位秒，默认1秒 periodSeconds: 0 #对容器监控检查的定期探测时间设置，单位秒，默认10秒一次 successThreshold: 0 failureThreshold: 0 securityContext: privileged: false restartPolicy: [Always | Never | OnFailure] #Pod的重启策略，Always表示一旦不管以何种方式终止运行，kubelet都将重启，OnFailure表示只有Pod以非0退出码退出才重启，Nerver表示不再重启该Pod nodeSelector: obeject #设置NodeSelector表示将该Pod调度到包含这个label的node上，以key：value的格式指定 imagePullSecrets: #Pull镜像时使用的secret名称，以key：secretkey格式指定 - name: string hostNetwork: false #是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络 volumes: #在该pod上定义共享存储卷列表 - name: string #共享存储卷名称 （volumes类型有很多种） emptyDir: {} #类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。为空值 hostPath: string #类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录 path: string #Pod所在宿主机的目录，将被用于同期中mount的目录 secret: #类型为secret的存储卷，挂载集群与定义的secre对象到容器内部 scretname: string items: - key: string path: string configMap: #类型为configMap的存储卷，挂载预定义的configMap对象到容器内部 name: string items: - key: string path: string Deployment文件定义 apiVersion: extensions/v1beta1 kind: Deployment metadata: \u003cObject\u003e spec: \u003cObject\u003e minReadySeconds: \u003cinteger\u003e #设置pod准备就绪的最小秒数 paused: \u003cboolean\u003e #表示部署已暂停并且deploy控制器不会处理该部署 progressDeadlineSeconds: \u003cinteger\u003e strategy: \u003cObject\u003e #将现有pod替换为新pod的部署策略 rollingUpdate: \u003cObject\u003e #滚动更新配置参数，仅当类型为RollingUpdate maxSurge: \u003cstring\u003e #滚动更新过程产生的最大pod数量，可以是个数，也可以是百分比 maxUnavailable: \u003cstring\u003e # type: \u003cstring\u003e #部署类型，Recreate，RollingUpdate replicas: \u003cinteger\u003e #pods的副本数量 selector: \u003cObject\u003e #pod标签选择器，匹配pod标签，默认使用pods的标签 matchLabels: \u003cmap[string]string\u003e key1: value1 key2: value2 matchExpressions: \u003c[]Object\u003e operator: \u003cstring\u003e -required- #设定标签键与一组值的关系，In, NotIn, Exists and DoesNotExist key: \u003cstring\u003e -required- values: \u003c[]string\u003e revisionHistoryLimit: \u003cinteger\u003e #设置保留的历史版本个数，默认是10 rollbackTo: \u003cObject\u003e revision: \u003cinteger\u003e #设置回滚的版本，设置为0则回滚到上一个版本 template: \u003cObject\u003e -required- metadata: spec: containers: \u003c[]Object\u003e #容器配置 - name: \u003cstring\u003e -required- #容器名、DNS_LABEL image: \u003cstring\u003e #镜像 imagePullPolicy: \u003cstring\u003e #镜像拉取策略，Always、Never、IfNotPresent ports: \u003c[]Object\u003e - name: #定义端口名 containerPort: #容器暴露的端口 protocol: TCP #或UDP volumeMounts: \u003c[]Object\u003e - name: \u003cstring\u003e -required- #设置卷名称 mountPath: \u003cstring\u003e -required- #设置需要挂载容器内的路径 readOnly: \u003cboolean\u003e #设置是否只读 livenessProbe: \u003cObject\u003e #就","date":"2023-06-09","objectID":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/:7:3","tags":null,"title":"Kubernetes 的注册中心和配置中心(Etcd))","uri":"/kubernetes%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%92%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83etcd/"},{"categories":null,"content":"MyBatis 是一款优秀的持久层框架，它支持自定义 SQL、存储过程以及高级映射。本文章主要是讲述如何集成 MyBatis 及其扩展框架，清楚地讲述 Mybatis、Mybatis Plus 和 Fluent MyBatis 的 CRUD 操作。最后将三者的使用性能做了一个对比，在实际开发过程中，建议使用原生的 MyBatis，具有较强的扩展性，并且其性能较高；当然，如果你追求高效的开发效率，建议使用 MyBatis Plus。 ","date":"2023-04-20","objectID":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/:0:0","tags":null,"title":"MyBatis 各个框架集成和性能对比","uri":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/"},{"categories":null,"content":"多数据源配置(通用) 数据库读写分离实现方案 通过Mybatis配置文件 通过MyBatis配置文件创建读写分离两个DataSource，每个SqlSessionFactoryBean对象的mapperLocations属性制定两个读写数据源的配置文件。将所有读的操作配置在读文件中，所有写的操作配置在写文件中。 通过Spring AOP 通过Spring AOP在业务层实现读写分离，在DAO层调用前定义切面，利用Spring的**AbstractRoutingDataSource**解决多数据源的问题，实现动态选择数据源 通过Mybatis的Plugin 通过Mybatis的Plugin在业务层实现数据库读写分离，在MyBatis创建Statement对象前通过拦截器选择真正的数据源，在拦截器中根据方法名称不同（select、update、insert、delete）选择数据源。 通过Spring的AbstractRoutingDataSource和Mybatis Plugin拦截器 如果你的后台结构是Spring + Mybatis，可以通过Spring的AbstractRoutingDataSource和Mybatis Plugin拦截器实现非常友好的读写分离，原有代码不需要任何改变 配置bootstrap.yml文件 spring: # 数据库组件 datasource: master: writer: type: com.alibaba.druid.pool.DruidDataSource # Druid数据库连接池 driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://${szt.database.writer.url}/customer_migration?charset=utf8mb4\u0026useSSL=false\u0026rewriteBatchedStatements=true\u0026autoReconnect=true username: ${szt.database.username} password: ${szt.database.password} testOnBorrow: true # 指明是否从池中取出连接前进行检验，如果检验失败，则从池中取出连接并尝试取出另一个 testOnReturn: true # 指明连接是否被空闲连接回收器（如果有）进行检验，如果检测失败，则连接将被从池中去除 testWhileIdle: true timeBetweenEvictionRunsMillis: 60000 # 在空闲连接回收器线程运行期间休眠的时间值，姨毫秒为单位。如果设置为非整数，则不运行空闲连接回收器线程 initialSize: 20 minIdle: 20 maxActive: 256 maxWait: 60000 # 配置获取连接等待超时的时间 minEvictableIdleTimeMillis: 300000 # 配置一个连接在池中最小生存的时间，单位是毫秒 validationQuery: SELECT'x' poolPreparedStatements: true # 打开PSCache，并且指定每个连接上PSCache的大小 maxPoolPreparedStatementPerConnectionSize: 20 filters: stat,wall,slf4j # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙，此处是filter修改的地方 reader: type: com.alibaba.druid.pool.DruidDataSource # Druid数据库连接池 driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://${szt.database.reader.url}/${szt.database.schema}?charset=utf8mb4\u0026useSSL=false\u0026rewriteBatchedStatements=true\u0026autoReconnect=true username: ${szt.database.username} password: ${szt.database.password} testOnBorrow: true # 指明是否从池中取出连接前进行检验，如果检验失败，则从池中取出连接并尝试取出另一个 testOnReturn: true # 指明连接是否被空闲连接回收器（如果有）进行检验，如果检测失败，则连接将被从池中去除 testWhileIdle: true timeBetweenEvictionRunsMillis: 60000 # 在空闲连接回收器线程运行期间休眠的时间值，姨毫秒为单位。如果设置为非整数，则不运行空闲连接回收器线程 initialSize: 20 minIdle: 20 maxActive: 256 maxWait: 60000 # 配置获取连接等待超时的时间 minEvictableIdleTimeMillis: 300000 # 配置一个连接在池中最小生存的时间，单位是毫秒 validationQuery: SELECT'x' poolPreparedStatements: true # 打开PSCache，并且指定每个连接上PSCache的大小 maxPoolPreparedStatementPerConnectionSize: 20 filters: stat,wall,slf4j # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙，此处是filter修改的地方 配置多数据源DataSourceConfig @Configuration public class DataSourceConfig { @Primary @Bean(name = \"writerDataSource\") @ConfigurationProperties(prefix = \"spring.datasource.master.writer\") public DataSource writerDataSource() { return new DruidDataSource(); } @Bean(name = \"readerDataSource\") @ConfigurationProperties(prefix = \"spring.datasource.master.reader\") public DataSource readerDataSource() { return new DruidDataSource(); } } 全局动态数据源枚举 /** * 全局动态数据源实体 */ public enum DataSourceEnum { READ, WRITE; } 配置DynamicDataSourceHolder /** * 动态数据源线程持有者 */ public final class DynamicDataSourceHolder { private static final ThreadLocal\u003cDataSourceEnum\u003e holder = new ThreadLocal\u003c\u003e(); /** * 设置当前线程使用的数据源 */ public static void putDataSource(DataSourceEnum dataSource) { holder.set(dataSource); } /** * 获取当前线程需要使用的数据源 */ public static DataSourceEnum getDataSource() { return holder.get(); } /** * 清空使用的数据源 */ public static void clearDataSource() { holder.remove(); } } 动态数据源DynamicDataSource /** * 动态数据源（继承自spring抽象动态路由数据源） */ public class DynamicDataSource extends AbstractRoutingDataSource { private DataSource writeDataSource; //写数据源 private DataSource readDataSource; //读数据源 /** * 在初始化之前被调用，设置默认数据源，以及数据源资源（这里的写法是参考源码中的） */ @Override public void afterPropertiesSet() { //如果写数据源不存在，则抛出非法异常 if (this.writeDataSource == null) { throw new IllegalArgumentException(\"Property 'writeDataSource' is required\"); } //设置默认目标数据源为主库 setDefaultTargetDataSource(writeDataSource); Map\u003cObject, Object\u003e targetDataSources = new HashMap\u003c\u003e(); targetDataSources.put(DataSourceEnum.WRITE.name(), write","date":"2023-04-20","objectID":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/:1:0","tags":null,"title":"MyBatis 各个框架集成和性能对比","uri":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/"},{"categories":null,"content":"Mybatis ","date":"2023-04-20","objectID":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/:2:0","tags":null,"title":"MyBatis 各个框架集成和性能对比","uri":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/"},{"categories":null,"content":"单表操作 Insert Method 1： XML文件 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"\u003e \u003cmapper namespace=\"com.sztus.mybatis.mapper.CustomerMapper\"\u003e \u003c!-- parameterType为入参的参数类型，开启useGeneratedKeys，返回主键id --\u003e \u003cinsert id=\"insertCustomer\" parameterType=\"com.sztus.mybatis.entity.Customer\" useGeneratedKeys=\"true\" keyProperty=\"id\"\u003e insert into customer (status, created_at, updated_at, unique_code) values (#{status}, #{createdAt}, #{updatedAt}, #{uniqueCode}) \u003c/insert\u003e \u003c/mapper\u003e @Mapper public interface CustomerMapper { int insertCustomer(Customer customer); } Method 2： SQL语句构造器 + JAVA API SQL语句构造方法 public class InformationSql { public String insertCustomerSql(Customer customer) { return new SQL() .INSERT_INTO(\"customer\") .INTO_COLUMNS(\"status\", \"created_at\", \"updated_at\", \"unique_code\") .INTO_VALUES(String.valueOf(customer.getStatus()), String.valueOf(customer.getCreatedAt()), String.valueOf(customer.getUpdatedAt()), customer.getUniqueCode()).toString(); } } Mapper通过注解的形式指向SQL语句 @Mapper public interface CustomerMapper { @InsertProvider(type = InformationSql.class, method = \"insertCustomerSql\") @SelectKey(statement = \"select LAST_INSERT_ID()\", keyProperty = \"id\", before = false, resultType = Long.class) int insertCustomerBySql(Customer customer); } Service调用Mapper @Service public class InformationService { @Autowired private CustomerMapper customerMapper; public int insertCustomer(Customer customer) { return customerMapper.insertCustomerBySql(customer); } } Method 3： 注解式 @Insert(\"insert into customer (status, created_at, updated_at, unique_code)\\n\" + \" values (#{status}, #{createdAt}, #{updatedAt}, #{uniqueCode})\") // 返回主键id @SelectKey(statement = \"select LAST_INSERT_ID()\", keyProperty = \"id\", before = false, resultType = Long.class) int insertCustomerByAnnotation(Customer customer); 注意：Mybatis提供3种新增数据的方式，返回结果是影响的行数，如果想要获取新增数据的主键id，需要加上对应的参数或者注解，并从对象中获取主键id Delete Method 1： XML文件 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"\u003e \u003cmapper namespace=\"com.sztus.mybatis.mapper.CustomerMapper\"\u003e \u003cdelete id=\"deleteCustomerById\"\u003e DELETE FROM customer WHERE id = #{id} \u003c/delete\u003e \u003c/mapper\u003e @Mapper public interface CustomerMapper { int deleteCustomerById(Long customerId); } Method2： SQL语句构造器 + JAVA API public String deleteCustomerSql(Long customerId) { return new SQL() .DELETE_FROM(\"customer\") .WHERE(\"id = \" + customerId) .toString(); } @Mapper public interface CustomerMapper { @InsertProvider(type = InformationSql.class, method = \"deleteCustomerSql\") int deleteCustomerBySql(Long customerId); } Method 3： 注解式 @Mapper public interface CustomerMapper { @Delete(\"DELETE FROM customer WHERE id = #{id}\") int deleteCustomerByAnnotation(Long customerId); } Update Method 1： XML文件 \u003c!-- 单条数据更新 --\u003e \u003cupdate id=\"updateCustomer\" parameterType=\"com.sztus.mybatis.entity.Customer\"\u003e UPDATE customer SET unique_code = #{customer.uniqueCode} WHERE id = #{customer.id} \u003c/update\u003e \u003c!-- 批量数据更新 --\u003e \u003cupdate id=\"batchUpdateCustomer\"\u003e \u003cforeach collection=\"list\" item=\"item\" open=\"\" close=\"\" separator=\";\"\u003e update customer \u003cset\u003e \u003cif test=\"item.status != null\"\u003estatus = #{item.status},\u003c/if\u003e \u003cif test=\"item.uniqueCode != null\"\u003eunique_code = #{item.uniqueCode},\u003c/if\u003e \u003cif test=\"item.createdAt != null\"\u003ecreated_at = #{createdAt},\u003c/if\u003e \u003cif test=\"item.updatedAt != null\"\u003eupdated_at = #{item.updatedAt},\u003c/if\u003e \u003c/set\u003e where id = #{item.id} \u003c/foreach\u003e \u003c/update\u003e Method 2： SQL语句构造器 + JAVA API public String updateCustomerSql(Customer customer) { return new SQL() .UPDATE(\"customer\") .SET(\"unique_code = \" + customer.getUniqueCode()) .WHERE(\"id = \" + customer.getId()) .toString(); } @Mapper public interface CustomerMapper { @Update(\"UPDATE customer SET unique_code = #{customer.uniqueCode} WHERE id = #{customer.id}\") int updateCustomerByAnnotation(Customer customer); } Method 3：注解式 @Mapper public interface CustomerMapper { @U","date":"2023-04-20","objectID":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/:2:1","tags":null,"title":"MyBatis 各个框架集成和性能对比","uri":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/"},{"categories":null,"content":"多表操作（动态SQL） XML方式进行多表的CRUD 动态SQL \u003cresultMap id=\"CustomerAccountMap\" type=\"com.jiafei.object.view.CustomerAccountView\"\u003e \u003cid column=\"id\" property=\"id\"/\u003e \u003cresult column=\"customer_id\" property=\"customerId\"\u003e\u003c/result\u003e \u003cresult column=\"account_status\" property=\"accountStatus\"\u003e\u003c/result\u003e \u003cresult column=\"identifier\" property=\"identifier\"\u003e\u003c/result\u003e \u003cresult column=\"portfolio_id\" property=\"portfolioId\"\u003e\u003c/result\u003e \u003cresult column=\"open_id\" property=\"openId\"\u003e\u003c/result\u003e \u003cresult column=\"customer_no\" property=\"customerNo\"\u003e\u003c/result\u003e \u003c/resultMap\u003e \u003cselect id=\"listCustomerAccount\" resultMap=\"CustomerAccountMap\"\u003e select * from customer_account_info where account_status = #{status} and customer_id in \u003cforeach collection=\"customerIds\" item=\"customerId\" index=\"index\" separator=\",\" open=\"(\" close=\")\"\u003e #{customerId} \u003c/foreach\u003e \u003c/select\u003e \u003cselect id=\"getLoan\" resultType=\"com.sztus.mybatis.object.view.GetLoanResult\"\u003e SELECT t1.loan_no, t1.id, t1.account_id, t2.email, t2.zip FROM loan t1 LEFT JOIn loan_personal_data t2 ON t1.id = t2.loan_id WHERE t2.email = #{email} \u003cif test=\"type != null and type != ''\"\u003e AND t1.type = #{type} \u003c/if\u003e \u003c/select\u003e \u003c!-- 使用 set+if 标签修改后，如果某项为 null 则不进行更新，而是保持数据库原值 --\u003e \u003cupdate id=\"updateStudent\" parameterType=\"com.sztus.mybatis.entity.Customer\"\u003e UPDATE customer \u003cset\u003e \u003cif test=\"status != null and status != ''\"\u003e status = #{customer.status}, \u003c/if\u003e \u003cif test=\"createdAt != null and createdAt != ''\"\u003e created_at = #{customer.createdAt}, \u003c/if\u003e \u003cif test=\"uniqueCode != null and uniqueCode != ''\"\u003e unique_code = #{customer.uniqueCode} \u003c/if\u003e \u003c/set\u003e WHERE id = #{customer.id}; \u003c/update\u003e \u003cselect id=\"getStudentListWhere\" resultType=\"com.sztus.mybatis.entity.Customer\"\u003e SELECT * from customer \u003cwhere\u003e \u003cif test=\"uniqueCode != null and uniqueCode != ''\"\u003e unique_code = #{uniqueCode} \u003c/if\u003e \u003cif test=\"id != null and id != ''\"\u003e AND id = #{id} \u003c/if\u003e \u003c/where\u003e \u003c/select\u003e \u003c!-- 当 uniqueCode 值为 null 时，查询语句会出现 “WHERE AND” 的情况，解决该情况除了将\"WHERE\"改为“WHERE 1=1”之外，还可以利用 where标签。这个“where”标签会知道如果它包含的标签中有返回值的话，它就插入一个‘where’。此外，如果标签返回的内容是以 AND 或 OR 开头的，则它会剔除掉。 --\u003e \u003cselect id=\"getStudentListWhere\" resultType=\"com.sztus.mybatis.entity.Customer\"\u003e SELECT * from customer \u003cwhere\u003e \u003cif test=\"uniqueCode != null and uniqueCode != ''\"\u003e unique_code = #{uniqueCode} \u003c/if\u003e \u003cif test=\"id != null and id != ''\"\u003e AND id = #{id} \u003c/if\u003e \u003c/where\u003e \u003c/select\u003e 批量插入 \u003cupdate id=\"batchUpdateCustomer\" parameterType=\"list\"\u003e \u003cforeach collection=\"list\" item=\"item\" open=\"\" close=\"\" separator=\";\"\u003e update customer \u003cset\u003e \u003cif test=\"item.status != null\"\u003estatus = #{item.status},\u003c/if\u003e \u003cif test=\"item.uniqueCode != null\"\u003eunique_code = #{item.uniqueCode},\u003c/if\u003e \u003cif test=\"item.createdAt != null\"\u003ecreated_at = #{createdAt},\u003c/if\u003e \u003cif test=\"item.updatedAt != null\"\u003eupdated_at = #{item.updatedAt},\u003c/if\u003e \u003c/set\u003e where id = #{item.id} \u003c/foreach\u003e \u003c/update\u003e \u003c!-- separator：分隔符，表示迭代时每个元素之间以什么分隔 open：前缀 close：后缀 --\u003e \u003cinsert id=\"insertBatch\" parameterType=\"java.util.List\"\u003e INSERT INTO customer (status, created_at, updated_at, unique_code) VALUES \u003cforeach collection=\"list\" item=\"item\" index=\"index\" separator=\",\" open=\"(\" close=\")\"\u003e #{item.status}, #{item.createdAt}, #{item.updatedAt}, #{item.uniqueCode} \u003c/foreach\u003e \u003c/insert\u003e 使用SQL语句构造器进行多表CRUD 不推荐，过于复杂 关联查询 批量插入 ","date":"2023-04-20","objectID":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/:2:2","tags":null,"title":"MyBatis 各个框架集成和性能对比","uri":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/"},{"categories":null,"content":"事物支持 需要替换spring事务管理器的数据源 @Bean public DataSourceTransactionManager transactionManager() { DataSourceTransactionManager dataSourceTransactionManager = new DataSourceTransactionManager(); // 替换为自定义的动态数据源 dataSourceTransactionManager.setDataSource(getDynamicDataSource()); return dataSourceTransactionManager; } 在需要加事务的方法，加上注解@Transactional @Transactional(rollbackFor = Exception.class) public void insertCustomer(Customer customer) { customerMapper.insertCustomerBySql(customer); Long idA = customer.getId(); /** * 程序运行带这一步，事务还未提交，数据库无法查出idA的数据 */ System.out.println(idA); customerMapper.insertCustomerBySql(customer); Long idB = customer.getId(); System.out.println(idB); } ","date":"2023-04-20","objectID":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/:2:3","tags":null,"title":"MyBatis 各个框架集成和性能对比","uri":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/"},{"categories":null,"content":"Mybatis Plus MyBatis-Plus是一个MyBatis的增强工具，在MyBatis的基础上只做增强不做改变，为简化开发、提高效率而生。 ","date":"2023-04-20","objectID":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/:3:0","tags":null,"title":"MyBatis 各个框架集成和性能对比","uri":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/"},{"categories":null,"content":"使用CRUD接口进行单表操作 Insert 单条插入 @Mapper public interface UserMapper extends BaseMapper\u003cUser\u003e { } @Service public class UserService { @Autowired private UserMapper userMapper; public void insertUser(User user) { userMapper.insert(user); } } Mybatis-plus默认存储完数据后,自动向传进来的实体类塞入主键ID，所以理论上无需做多余的配置 批量插入 @Service public class UserService { @Autowired private UserMapper userMapper; public void insertBatch(List\u003cUser\u003e list) { userMapper.insertBatch(list); } } Delete 单条删除 @Service public class UserService { @Autowired private UserMapper userMapper; // row为影响行数 public void deleteUserById(Long id) { // 1、通过指定条件删除 Map\u003cString, Object\u003e condition = new HashMap\u003c\u003e(); condition.put(\"id\", id); int affectRowA = userMapper.deleteByMap(condition); // 2、通过主键删除 int affectRowB = userMapper.deleteById(id); // 3、通过实体类删除 User user = new User(); user.setId(id); int affectRowC = userMapper.deleteById(user); // 4、通过QueryWrapper删除 QueryWrapper\u003cUser\u003e userQueryWrapper = new QueryWrapper\u003c\u003e(); // 此处可以使用 userQueryWrapper.allEq(condition); userQueryWrapper.eq(\"id\", id); int affectRowD = userMapper.delete(userQueryWrapper); } } 批量删除 @Service public class UserService { @Autowired private UserMapper userMapper; // row为影响行数 public void deleteUserBatch(List\u003cUser\u003e list) { // 1、通过主键id去删除 List\u003cLong\u003e userIdList = list.parallelStream() .map(User::getId) .collect(Collectors.toList()); int affectRowA = userMapper.deleteBatchIds(userIdList); // 2、通过QueryWrapper批量删除 QueryWrapper\u003cUser\u003e userQueryWrapper = new QueryWrapper\u003c\u003e(); userQueryWrapper.in(\"id\", userIdList); userMapper.delete(userQueryWrapper); } } 备注：还可以通过集成ServiceImpl类或者调用Db类的静态方法（3.5.3版本之后），调用如下图所示的方法删除你想删除的数据。 Update @Service public class UserService extends ServiceImpl\u003cUserMapper, User\u003e { @Autowired private UserMapper userMapper; public void updateUser(User user) { // 1、通过id更新，单条数据的更新 int affectRowA = userMapper.updateById(user); // 2、通过条件更新，批量数据的更新 UpdateWrapper\u003cUser\u003e userUpdateWrapper = new UpdateWrapper\u003c\u003e(); userUpdateWrapper.eq(\"id\", user.getId()); int affectRowB = userMapper.update(user, userUpdateWrapper); // 3、更新或者插入新的数据 this.saveOrUpdate(user); } } Query @Service public class UserService extends ServiceImpl\u003cUserMapper, User\u003e { @Autowired private UserMapper userMapper; public void select(Long id, String openId, String email) { // 1、通过主键id查询 User userA = userMapper.selectById(id); // 2、通过条件查询单挑数据 QueryChainWrapper\u003cUser\u003e queryChainWrapper = query().eq(\"open_id\", openId); User userB = userMapper.selectOne(queryChainWrapper); // 3、通过Id批量查询 List\u003cLong\u003e idList = new ArrayList\u003c\u003e(); idList.add(id); List\u003cUser\u003e userListA = userMapper.selectBatchIds(idList); QueryWrapper\u003cUser\u003e userQueryWrapper = new QueryWrapper\u003c\u003e(); userQueryWrapper.eq(\"email\", email); // 4、查询满足条件的数量 Long count = userMapper.selectCount(userQueryWrapper); // 5、批量查询email List\u003cUser\u003e userListB = userMapper.selectList(userQueryWrapper); // 6、selectObjs只返回第一个字段的值 // 这里虽然知道了返回两列数据，但是只会返回name字段 userQueryWrapper.select(\"name\", \"age\"); List\u003cObject\u003e list = userMapper.selectObjs(userQueryWrapper); } } ","date":"2023-04-20","objectID":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/:3:1","tags":null,"title":"MyBatis 各个框架集成和性能对比","uri":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/"},{"categories":null,"content":"其他 条件构造器 Mybatis-Plus具有丰富的条件构造器，满足各种常见的需求，语法简单易懂，并且支持链式调用。 Map\u003cString, Object\u003e condition = new HashMap\u003c\u003e(); condition.put(\"id\", \"123\"); condition.put(\"open_id\", \"0a4b2fd66e95482cba3071ff4fa0db7b\"); QueryWrapper\u003cUser\u003e queryWrapper = new QueryWrapper\u003c\u003e(); queryWrapper // 要查询字段 .select(\"id\", \"name\", \"email\", \"open_id\") // 等于，默认用AND链接，id = 123 AND open_id = '0a4b2fd66e95482cba3071ff4fa0db7b' .eq(\"id\", 123).eq(\"open_id\", \"0a4b2fd66e95482cba3071ff4fa0db7b\") // 全部eq，与上述条件一致，id = 123 AND open_id = '0a4b2fd66e95482cba3071ff4fa0db7b' .allEq(condition) // 不等于， name != 'XXX' .ne(\"name\", \"XXX\") // 大于，age \u003e 18，大于等于用ge()方法 .gt(\"age\", 18) // 小于等于，age \u003c= 50 .le(\"age\", 50) // age BETWEEN 18 AND 50 .between(\"age\", 18, 50) // 模糊查询，email LIKE %@sztus% // 左右模糊查询调用likeLeft()和likeRight()方法，不匹配用notLikeLeft()和notLikeRight() .like(\"email\", \"@sztus\") // 条件为NULL，address IS NULL // 不为空用isNotNull .isNull(\"address\") // city IN ('chengdu', 'chongqing')，也可以传List，不在集合中用notIn .in(\"city\", \"chengdu\", \"chongqing\") // 或者，下面的条件表示 OR (email = 'test@sztus.com') .or(i -\u003e i.eq(\"email\", \"test@sztus.com\")) // GROUP BY name, age，排序用orderBy()，orderByDesc()，orderByAsc() .groupBy(\"name\", \"age\") // 根据判断结果，动态拼接条件 .func( i -\u003e { if(true) { i.eq(\"id\", 1); } else { i.ne(\"id\", 1); } } ) // 无视优化规则直接拼接到 sql 的最后 .last(\"LIMIT 1\"); 分页插件 方案一（不推荐）：使用Mybatis-Plus自带的分页方法 public Page\u003cUser\u003e select() { QueryWrapper\u003cUser\u003e queryWrapper = new QueryWrapper\u003c\u003e(); queryWrapper.eq(\"email\", \"test@sztus.com\"); Page\u003cUser\u003e userPage = new Page\u003c\u003e(1, 10); userMapper.selectPage(userPage, queryWrapper); return userPage; } 该方法先查出所有符合条件的数据，拿到结果集后，通过自带的方法，处理得到具体某一页的数据。在数据量较大的情况下，会严重影响性能。 方案二（推荐）：通过条件构造器的last()方法，在条件最后加上LIMIT，拼接分页参数 public List\u003cUser\u003e select() { QueryWrapper\u003cUser\u003e queryWrapper = new QueryWrapper\u003c\u003e(); queryWrapper.eq(\"email\", \"test@sztus.com\"); queryWrapper.last(\"LIMIT 1, 10\"); List\u003cUser\u003e list = userMapper.selectList(queryWrapper); return list; } ","date":"2023-04-20","objectID":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/:3:2","tags":null,"title":"MyBatis 各个框架集成和性能对比","uri":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/"},{"categories":null,"content":"Fluent Mybatis 基于mybatis但青出于蓝 No XML, No Mapper, No If else, No String魔法值编码 只需Entity就实现强大的FluentAPI: 支持分页, 嵌套查询, AND OR组合, 聚合函数… ","date":"2023-04-20","objectID":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/:4:0","tags":null,"title":"MyBatis 各个框架集成和性能对比","uri":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/"},{"categories":null,"content":"使用逆向工程对服务进行构建 逆向工程生成对应实体 public class Generator { static final String url = \"jdbc:mysql:xxxxxxxxx\"; public static void main(String[] args) { FileGenerator.build(generator.class); } @Tables( /** 数据库连接信息 **/ url = url, username = \"xxxxxxxxx\", password = \"xxxxxxxxx\", /** 包名 **/ basePack = \"com.example.demo\", /** 生成Entity代码目录 如果为聚合项目记得加上子包名 **/ srcDir = \"/demo4/src/main/java\", /** 生成Dao代码目录 **/ daoDir = \"/demo4/src/main/java\", /** 定义创建，修改，逻辑删除字段 **/ gmtCreated = \"create\", gmtModified = \"modified\", logicDeleted = \"is_del\", /** 需要生成文件的表, 这里可以配置多个表 **/ tables = @Table(value = {\"customer\",\"customer_account_info\"}) ) static class generator { } } @Data @Accessors( chain = true ) @EqualsAndHashCode( callSuper = false ) @FluentMybatis( table = \"customer\", schema = \"customer\" ) public class CustomerEntity extends RichEntity { private static final long serialVersionUID = 1L; @TableId(\"id\") private Long id; @TableField(\"category\") private Integer category; @TableField(\"created_at\") private Long createdAt; @TableField(\"source\") private Integer source; @TableField(\"status\") private Integer status; @TableField(\"unique_code\") private String uniqueCode; @TableField(\"updated_at\") private Long updatedAt; @Override public final Class entityClass() { return CustomerEntity.class; } } 注：也可不用逆向工程，但需要在对应Entity写好注解，以用于在target中生成mapper和wrapper文件 build项目以生成对应mapper和wrapper文件 ","date":"2023-04-20","objectID":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/:4:1","tags":null,"title":"MyBatis 各个框架集成和性能对比","uri":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/"},{"categories":null,"content":"使用API进行单表操作 Insert 单条插入 void insertTest() { long currentTimeMillis = System.currentTimeMillis(); CustomerEntity customerEntity = new CustomerEntity() .setStatus(1) .setSource(1) .setUniqueCode(UUID.randomUUID().toString().toUpperCase(Locale.ROOT)) .setCreatedAt(currentTimeMillis) .setUpdatedAt(currentTimeMillis); //使用save()方法进行插入数据 int save = customerMapper.save(customerEntity); // int save = customerMapper.insertWithPk(customerEntity); // int save = customerMapper.insert(customerEntity); // Boolean save = customerMapper.saveOrUpdate(customerEntity); } *注:insert(), insertWithPk(), save()三种方法用于插入数据，saveOrUpdate()方法用于通过判断有无主键来进行插入或保存修改 当使用insert()方法进行插入数据时，实体类中不能有主键数据，使用insertWithPk()方法时必须有主键数据，否则会抛异常。 save()方法是insert和insertWithPk的简便方法，自动判断Entity是否已经有主键值，但save()不能进行数据修改，会报主键冲突异常 批量插入 void insertBatchTest(List\u003cCustomerEntity\u003e customerList){ int result = customerMapper.save(customerList); // int result = customerMapper.insertBatch(customerList); // int result = customerMapper.insertBatchWithPk(customerList); } 注意：当使用insertBatch()方法进行批量插入数据时，实体集合中不能有主键数据，使用insertBatchWithPk()方法时必须有主键数据，否则会抛异常。save(Collection\u003cE\u003e list)方法是insertBatch()和insertBatchWithPk()的简便方法，自动判断数据集合是否已经有主键值，但应确保集合中实体的主键数据全有或全无，否则抛出异常。save(Collection\u003cE\u003e list)不能进行数据修改，会报主键冲突异常 Delete void deleteTest(){ //通过主键删除 customerMapper.deleteById(2028); } void deleteTest(){ //通过主键集合删除 customerMapper.deleteByIds(Arrays.asList(2027,2028)); } void deleteTest(){ //根据Map\u003cString,Object\u003e设置是键值对删除数据 customerMapper.deleteByMap(true, new HashMap\u003cString, Object\u003e() { { this.put(\"id\", 2027); } }); } void deleteTest(){ //根据自定义条件物理删除数据 CustomerQuery update = new CustomerQuery() .where.id().in(Arrays.asList(2027,2028)).end(); customerMapper.delete(update); // DELETE FROM customer WHERE id IN (2027,2028) } Update void updateTest() { //按Entity的主键更新Entity中非空字段 long currentTimeMillis = System.currentTimeMillis(); CustomerEntity customerEntity = new CustomerEntity() .setId(1102L) .setStatus(0) .setSource(0) .setUniqueCode(UUID.randomUUID().toString().toUpperCase(Locale.ROOT)) .setCreatedAt(currentTimeMillis) .setUpdatedAt(currentTimeMillis); customerMapper.updateById(customerEntity); } void updateTest() { //自定义更改指定字段数据与筛选条件(会写入空值到库中) CustomerUpdate update = new CustomerUpdate() .set.status().is(0).updatedAt().is(System.currentTimeMillis()).end() //set 指定修改的字段与数据 .where.id().eq(1102).end(); // where 指定筛选条件 // UPDATE customer SET `status` = 0, updated_at = 1676516452634 WHERE id = 1102 customerMapper.updateBy(update); } void updateTest() throws Exception { //批量修改数据 IUpdate[] updates = this.assembleCustomerUpdate(this.getCustomerList()).toArray(new IUpdate[0]); int count = customerMapper.updateBy(updates); System.out.println(count); } private List\u003cIUpdate\u003e assembleCustomerUpdate(List\u003cCustomerEntity\u003e customerEntities) throws Exception { //组装批量修改的updater ArrayList\u003cIUpdate\u003e result = new ArrayList\u003c\u003e(); for (CustomerEntity customerEntity : customerEntities) { if (Objects.isNull(customerEntity.getId())){ throw new Exception(\"PRIMARY Key Can Not Be Null\"); } // 将每个实体都组装成通过主键修改的修改器 IUpdate update = SqlKitFactory.factory(customerMapper).updateById(customerMapper.mapping(), customerEntity); result.add(update); } return result; } private List\u003cCustomerEntity\u003e getCustomerList() { long currentTimeMillis = System.currentTimeMillis(); CustomerEntity customerEntity1 = new CustomerEntity() .setId(2027l) .setStatus(0) .setSource(0) .setUniqueCode(UUID.randomUUID().toString().toUpperCase(Locale.ROOT)) .setCreatedAt(currentTimeMillis) .setUpdatedAt(currentTimeMillis); CustomerEntity customerEntity2 = new CustomerEntity() .setId(2028l) .setStatus(0) .setSource(0) .setUniqueCode(UUID.randomUUID().toString().toUpperCase(Locale.ROOT)) .setCreatedAt(currentTimeMillis) .setUpdatedAt(currentTimeMillis); List\u003cCustomerEntity\u003e list = new ArrayList() {{ add(customerEntity1); add(customerEntity2); }}; return list; } Query void queryTest() { //根据主键查询数据 CustomerEntity customer = customerMapper.findById(2028); // SELECT * FROM customer ","date":"2023-04-20","objectID":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/:4:2","tags":null,"title":"MyBatis 各个框架集成和性能对比","uri":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/"},{"categories":null,"content":"使用API进行多表操作 void queryTest() { //联表查询 最终结果只映射对应调用实体数据(如下只返回Customer对应的数据) CustomerQuery leftQuery = new CustomerQuery(\"a1\").selectAll() .where.id().in(Arrays.asList(238,283)) .end(); CustomerAccountInfoQuery rightQuery = new CustomerAccountInfoQuery(\"a2\") .where.portfolioId().eq(60) .end(); IQuery query = leftQuery .join(rightQuery) .on(l -\u003e l.where.id(), r -\u003e r.where.customerId()).endJoin() .build(); // SELECT * FROM customer a1 LEFT JOIN customer_account_info a2 on a1.id = a2.customer_id // WHERE a1.id in(238,283) and a2.portfolio_id = 60 List\u003cMap\u003cString, Object\u003e\u003e maps = customerMapper.listMaps(query); void queryTest() { //自定义sql查询 FreeQuery query = new FreeQuery(null).customizedByQuestion( \"SELECT * FROM customer a1 LEFT JOIN customer_account_info a2 on a1.id = a2.customer_id \" + \"WHERE a1.id = ? and a2.portfolio_id = ?\", 283, 60); List\u003cMap\u003cString, Object\u003e\u003e maps = customerMapper.listMaps(query); } ","date":"2023-04-20","objectID":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/:4:3","tags":null,"title":"MyBatis 各个框架集成和性能对比","uri":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/"},{"categories":null,"content":"性能对比 使用原生Mybatis和Mybatis-plus、Fluent-Mybatis封装好的方法，对数据库新增一批数据（备注：表字段20个，存在大字段，且需要维护索引），在数据量较少情况下，三种方式没有太多的差别，当数据量达到100条以上时，原生Mybatis通过foreach标签组装Sql的方式更快，数据量即使达到5000条，依然能在1秒内完成；而Fluent-Mybatis批量插入数据和Mybatis-Plus批量插入数据，需要花费较长的时间，数据量达到300条时，就会花费1秒左右，数据据量越大，花费的时间成倍数增长。 \u003cinsert id=\"insertBatch\" parameterType=\"java.util.List\"\u003e INSERT INTO user (name, age, gender, address, month_income, interest, city, open_id, password, salt, height, weight, careers, telephone, nationality, account_balance, email, key_name, ip, level ) VALUES \u003cforeach collection=\"list\" item=\"item\" index=\"index\" separator=\",\" \u003e (#{item.name}, #{item.age}, #{item.gender}, #{item.address}, #{item.monthIncome}, #{item.interest}, #{item.city}, #{item.openId}, #{item.password}, #{item.salt}, #{item.height}, #{item.weight}, #{item.careers}, #{item.telephone}, #{item.nationality}, #{item.accountBalance}, #{item.email}, #{item.keyName}, #{item.ip}, #{item.level}) \u003c/foreach\u003e \u003c/insert\u003e 数据量（条） 原生xml方式批量插入 Fluent-Mybatis批量插入 Mybatis-Plus批量插入 5 9 20 24 10 17 40 37 30 21 92 123 50 19 192 186 80 21 288 294 100 27 366 347 300 69 1026 1006 600 123 2200 2105 800 134 2945 2771 1000 174 3826 3244 2000 351 7573 6857 3000 456 10567 10557 5000 752 16791 16986 6000 950 20291 27171 ","date":"2023-04-20","objectID":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/:5:0","tags":null,"title":"MyBatis 各个框架集成和性能对比","uri":"/persistence-framework-mybatis-mybatis-plus-and-fluent-mybatis-2023-02-16/"},{"categories":null,"content":"概速 在现实项目中，我们往往会遇到需要使用多个 Redis 数据源的场景。本文介绍的是一种高度定制化的方案。每个独立的数据源都会使用自己的配置，其中包括针对该数据源的连接池配置。 ","date":"2022-06-18","objectID":"/redis-%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E9%85%8D%E7%BD%AE/:1:0","tags":null,"title":"Redis 多数据源读写分离配置","uri":"/redis-%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"yml 更新内容 redis: lettuce: pool: maxTotal: 200 minIdle: 1 maxWaitMillis: 5000 maxIdle: 5 testOnBorrow: true testOnReturn: true testWhileIdle: true primary: writer: database: ${jerry.redis.primary.writer.database} hostName: ${jerry.redis.primary.writer.url} port: ${jerry.redis.primary.writer.port} reader: database: ${jerry.redis.primary.reader.database} hostName: ${jerry.redis.primary.reader.url} port: ${jerry.redis.primary.reader.port} datasourceA: writer: database: ${jerry.redis.datasourceA.writer.database} hostName: ${jerry.redis.datasourceA.writer.url} port: ${ajerryrb.redis.datasourceA.writer.port} reader: database: ${jerry.redis.datasourceA.reader.database} hostName: ${jerry.redis.datasourceA.reader.url} port: ${jerry.redis.datasourceA.reader.port} datasourceB: writer: database: ${jerry.redis.datasourceB.writer.database} hostName: ${jerry.redis.datasourceB.writer.url} port: ${ajerryrb.redis.datasourceB.writer.port} reader: database: ${jerry.redis.datasourceB.reader.database} hostName: ${jerry.redis.datasourceB.reader.url} port: ${jerry.redis.datasourceB.reader.port} 在原有的配置下面增加 writer 和 reader。 在 profiles 中也要做相应的配置修改 ","date":"2022-06-18","objectID":"/redis-%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E9%85%8D%E7%BD%AE/:2:0","tags":null,"title":"Redis 多数据源读写分离配置","uri":"/redis-%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"Primary 数据源和 Redis Repository 配置 数据源配置 Configuration public class PrimaryRedisConfiguration { /** * 配置lettuce连接池 */ @Bean(name = \"redisPool\") @ConfigurationProperties(prefix = \"spring.redis.lettuce.pool\") @Scope(value = \"prototype\") public GenericObjectPoolConfig redisPool() { return new GenericObjectPoolConfig(); } @Bean(name = \"primaryReaderRedisConfig\") @ConfigurationProperties(prefix = \"spring.redis.primary.reader\") public RedisStandaloneConfiguration primaryReaderRedisConfig() { return new RedisStandaloneConfiguration(); } @Bean(name = \"primaryWriterRedisConfig\") @ConfigurationProperties(prefix = \"spring.redis.primary.writer\") @Primary public RedisStandaloneConfiguration primaryWriterRedisConfig() { return new RedisStandaloneConfiguration(); } @Bean(name = \"redisReaderConnectionFactory\") public LettuceConnectionFactory redisReaderConnectionFactory() { LettucePoolingClientConfiguration poolingClientConfiguration = LettucePoolingClientConfiguration.builder() .poolConfig(redisPool()) .build(); return new LettuceConnectionFactory(primaryReaderRedisConfig(), poolingClientConfiguration); } @Bean(name = \"primaryReaderRedisTemplate\") public StringRedisTemplate primaryReaderRedisTemplate() { StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisReaderConnectionFactory()); return template; } @Bean(name = \"redisWriterConnectionFactory\") @Primary public LettuceConnectionFactory redisWriterConnectionFactory() { LettucePoolingClientConfiguration poolingClientConfiguration = LettucePoolingClientConfiguration.builder() .poolConfig(redisPool()) .build(); return new LettuceConnectionFactory(primaryWriterRedisConfig(), poolingClientConfiguration); } @Bean(name = \"primaryWriterRedisTemplate\") @Primary public StringRedisTemplate primaryWriterRedisTemplate() { StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisWriterConnectionFactory()); return template; } } Redis Repository 配置，这是 Redis 基础操作类 @Repository public abstract class BaseRedisRepository { @Autowired @Qualifier(\"primaryReaderRedisTemplate\") private StringRedisTemplate readerRedisTemplate; @Autowired @Qualifier(\"primaryWriterRedisTemplate\") private StringRedisTemplate writerRedisTemplate; public StringRedisTemplate getReaderRedisTemplate() { return readerRedisTemplate; } public StringRedisTemplate getWriterRedisTemplate() { return writerRedisTemplate; } public String generateKey(String cacheKey, Object... options) { String idStr = connectArray(GlobalConst.STR_POUND, options); return String.format(\"%s@%s\", cacheKey, CryptUtil.md5(idStr)); } /** * 通过CacheKey 缓存字符串 * * @param cacheKey 缓存Key * @param dataStr 缓存数据 * @param expiredIn 过期时间（秒） * @param args 生成最终缓存key的参数 */ public void cacheString(String cacheKey, String dataStr, Long expiredIn, Object... args) { cacheKey = generateKey(cacheKey, args); set(cacheKey, dataStr, expiredIn); } /** * 根据传入Key获取对应String * * @param cacheKey 缓存建 * @param args 不定长参数 */ public String fetchString(String cacheKey, Object... args) { String result = null; cacheKey = generateKey(cacheKey, args); if (hasKey(cacheKey)) { result = get(cacheKey); } return result; } public static String connectArray(String separator, Object... args) { StringBuilder builder = new StringBuilder(); String s = GlobalConst.STR_EMPTY; if (Objects.nonNull(args)) { for (Object arg : args) { if (Objects.nonNull(arg)) { builder.append(s).append(arg); if (GlobalConst.STR_EMPTY.equals(s)) { s = separator; } } } } return builder.toString(); } public Integer set(String key, String value) { try { getWriterRedisTemplate().opsForValue().set(key, value); return CodeConst.SUCCESS; } catch (Exception e) { return CodeConst.FAILURE; } } public void set(String key, String value, Long timeout) { if (Objects.nonNull(timeout) \u0026\u0026 timeout \u003e 0) { getWriterRedisTemplate().opsForValue().set(key, value, timeout, TimeUnit.SECONDS); } else { getWriterRedisTemplate().opsForValue().set(key, value); } } public void setExpire(String key, Lon","date":"2022-06-18","objectID":"/redis-%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E9%85%8D%E7%BD%AE/:3:0","tags":null,"title":"Redis 多数据源读写分离配置","uri":"/redis-%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"Configuration 修改内容 如果需要配置多数据源，我们需要增加对应的 Redis 配置类 @Configuration public class DatasourceARedisConfiguration { @Bean @ConfigurationProperties(prefix = \"spring.redis.lettuce.pool\") @Scope(value = \"prototype\") public GenericObjectPoolConfig redisPool() { return new GenericObjectPoolConfig(); } private StringRedisTemplate getRedisTemplate() { StringRedisTemplate template = new StringRedisTemplate(); template.setValueSerializer(new GenericFastJsonRedisSerializer()); template.setValueSerializer(new StringRedisSerializer()); return template; } @Bean @ConfigurationProperties(prefix = \"spring.redis.datasourceA.reader\") public RedisStandaloneConfiguration datasourceAReaderRedisConfig() { RedisStandaloneConfiguration redisStandaloneConfiguration = new RedisStandaloneConfiguration(); redisStandaloneConfiguration.setDatabase(); return } @Bean public JedisConnectionFactory datasourceAReaderFactory() { LettucePoolingClientConfiguration poolingClientConfiguration = LettucePoolingClientConfiguration.builder() .poolConfig(redisPool()) .build(); return new LettuceConnectionFactory(primaryReaderRedisConfig(), poolingClientConfiguration); } @Bean(name = \"datasourceAReaderRedisTemplate\") public StringRedisTemplate datasourceAReaderRedisTemplate() { StringRedisTemplate template = getRedisTemplate(); template.setConnectionFactory(datasourceAReaderFactory()); return template; } @Bean @ConfigurationProperties(prefix = \"spring.redis.datasourceA.writer\") public RedisStandaloneConfiguration datasourceAWriterRedisConfig() { return new RedisStandaloneConfiguration(); } @Bean public JedisConnectionFactory datasourceAWriterFactory() { LettucePoolingClientConfiguration poolingClientConfiguration = LettucePoolingClientConfiguration.builder() .poolConfig(redisPool()) .build(); return new LettuceConnectionFactory(primaryWriterRedisConfig(), poolingClientConfiguration); } @Bean(name = \"datasourceAWriterRedisTemplate\") public StringRedisTemplate datasourceAWriterRedisTemplate() { StringRedisTemplate template = getRedisTemplate(); template.setConnectionFactory(datasourceAWriterFactory()); return template; } } 将原有的单一 authRedisTemplate 配置修改为读写分离的配置模式 ","date":"2022-06-18","objectID":"/redis-%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E9%85%8D%E7%BD%AE/:4:0","tags":null,"title":"Redis 多数据源读写分离配置","uri":"/redis-%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"RedisRepository 修改内容 @Repository public class DatasourceARedisRepository extends BaseRedisRepository { /** * 重写基类Repository中的方法，以切换成slave源，完成多数据源的配置 * @return StringRedisTemplate */ @Override protected StringRedisTemplate redisWriterTemplate() { return datasourceAWriterRedisTemplate; } /** * 重写基类Repository中的方法，以切换成slave源，完成多数据源的配置 * @return StringRedisTemplate */ @Override protected StringRedisTemplate redisReaderTemplate() { return datasourceAReaderRedisTemplate; } /** * 多数据源的配置。自动注入配置好的一个redis源的模板对象， * 此对象必须在配置类中进行配置，并且此处注入的bean name需要与配置一致 */ @Autowired @Qualifier(\"datasourceAWriterRedisTemplate\") private StringRedisTemplate datasourceAWriterRedisTemplate; /** * 多数据源的配置。自动注入配置好的一个redis源的模板对象， * 此对象必须在配置类中进行配置，并且此处注入的bean name需要与配置一致 */ @Autowired @Qualifier(\"datasourceAReaderRedisTemplate\") private StringRedisTemplate datasourceAReaderRedisTemplate; } 需要将 Configuration 里面读写的 StringRedisTemplate 注入到 RedisRepository 中 并按数据源重写 redisWriterTemplate 和 redisReaderTemplate 接口 示例: 使用写连接去执行读的操作 ","date":"2022-06-18","objectID":"/redis-%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E9%85%8D%E7%BD%AE/:5:0","tags":null,"title":"Redis 多数据源读写分离配置","uri":"/redis-%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E9%85%8D%E7%BD%AE/"}]